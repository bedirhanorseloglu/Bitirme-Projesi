{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 1- Drive Ba\u011flant\u0131s\u0131"
   ],
   "metadata": {
    "id": "_TJmniJ4-BiY"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NlvKn8KFO70n",
    "outputId": "53ead32d-78cc-440f-f9b1-5e41302d7e45"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2- K\u00fct\u00fcphaneler"
   ],
   "metadata": {
    "id": "IJZG5tfX0jbq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install pymap3d pyproj"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ja9w4PiNqKq",
    "outputId": "773d9808-8790-4e8c-8a60-cf04a3bfe910"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 1. Matematik ve Say\u0131sal \u0130\u015flemler\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.optimize # Optimizasyon i\u015flemleri i\u00e7in\n",
    "from scipy.spatial import distance # \u0130ki nokta aras\u0131ndaki mesafeleri hesaplamak i\u00e7in.\n",
    "from scipy import signal #  Sinyal i\u015fleme fonksiyonlar\u0131 i\u00e7in\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline # Veriler \u00fczerinde spline interpolasyonu yapmak i\u00e7in. Yani; noktalar aras\u0131nda d\u00fczg\u00fcn, kesintisiz ve p\u00fcr\u00fczs\u00fcz e\u011friler olu\u015fturur.\n",
    "\n",
    "# 2. G\u00f6rselle\u015ftirme ve Veri Analizi\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px # Etkile\u015fimli ve daha geli\u015fmi\u015f g\u00f6rselle\u015ftirmeler i\u00e7in.\n",
    "import plotly.graph_objects as go # Etkile\u015fimli ve daha geli\u015fmi\u015f g\u00f6rselle\u015ftirmeler i\u00e7in.\n",
    "\n",
    "# 3. Co\u011frafi Hesaplamalar\n",
    "import pymap3d as pm # GNSS konum verilerinin d\u00f6n\u00fc\u015ft\u00fcr\u00fclmesi ve Vincenty form\u00fclleri ile mesafe hesaplamalar\u0131 i\u00e7in.\n",
    "import pymap3d.vincenty as pmv #GNSS konum verilerinin d\u00f6n\u00fc\u015ft\u00fcr\u00fclmesi ve Vincenty form\u00fclleri ile mesafe hesaplamalar\u0131 i\u00e7in.\n",
    "import pyproj as proj # Co\u011frafi projeksiyonlar ve d\u00f6n\u00fc\u015f\u00fcmler i\u00e7in.\n",
    "\n",
    "# 4. Makine \u00d6\u011frenimi ve Derin \u00d6\u011frenme\n",
    "from tensorflow import keras # Derin \u00f6\u011frenme modelleri olu\u015fturmak ve e\u011fitmek i\u00e7in.\n",
    "from keras import layers # Yapay sinir a\u011flar\u0131 katmanlar\u0131n\u0131 tan\u0131mlamak ve olu\u015fturmak i\u00e7in .\n",
    "from keras import models # Yapay sinir a\u011flar\u0131 modellerini tan\u0131mlamak ve olu\u015fturmak i\u00e7in.\n",
    "\n",
    "# 5. Dosya ve \u0130lerleme Takibi\n",
    "import glob as gl # Dosya sistemi ile \u00e7al\u0131\u015fmak ve belirli desenlere uyan dosyalar\u0131 bulmak i\u00e7in.\n",
    "from tqdm.auto import tqdm # Uzun s\u00fcren i\u015flemlerde  ilerleme \u00e7ubu\u011fu olu\u015fturmak i\u00e7in.\n",
    "\n",
    "# 6. Gereksiz Uyar\u0131lar\u0131 G\u00f6rmeme\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# Sabitler\n",
    "CLIGHT = 299_792_458   # I\u015f\u0131k H\u0131z\u0131 (m/s). GNSS sinyallerinin uydu ile al\u0131c\u0131 aras\u0131nda hareket etme h\u0131z\u0131n\u0131 temsil edecek.\n",
    "RE_WGS84 = 6_378_137   # D\u00fcnya Yar\u0131\u00e7ap\u0131 (WGS84 y\u00f6ntemiyle \u00f6l\u00e7\u00fclm\u00fc\u015ft\u00fcr) (m). D\u00fcnya'n\u0131n WGS84 referans elipsoidine g\u00f6re ekvator yar\u0131\u00e7ap\u0131n\u0131 temsil edecek.\n",
    "OMGE = 7.2921151467E-5  # D\u00fcnya'n\u0131n A\u00e7\u0131sal H\u0131z\u0131 (rad/s). D\u00fcnya'n\u0131n kendi ekseni etraf\u0131ndaki d\u00f6n\u00fc\u015f h\u0131z\u0131n\u0131 temsil eder.  Konum hesaplamalar\u0131nda kullan\u0131l\u0131r."
   ],
   "metadata": {
    "id": "XLi8O0gTNsW5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3- Uydu Se\u00e7imi"
   ],
   "metadata": {
    "id": "I2l7iVhX1eG6"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Bu fonksiyon, bir GNSS veri \u00e7er\u00e7evesinden (\u00f6r. device_gnss.csv dosyas\u0131ndan al\u0131nan veriler) belirli kriterlere g\u00f6re uydu sinyallerini se\u00e7mek i\u00e7in kullan\u0131lacakt\u0131r.\n",
    "\n",
    "Fonksiyon, a\u015fa\u011f\u0131daki \u00f6l\u00e7\u00fctlere uymayan uydu sinyallerini filtreleyerek daha g\u00fcvenilir veriler elde edilmesini sa\u011flar:\n",
    "- **Ta\u015f\u0131y\u0131c\u0131 frekans hatas\u0131 (CarrierErrorHz) 2 MHz'ten k\u00fc\u00e7\u00fck olmal\u0131.** \u00c7\u00fcnk\u00fc, GNSS sinyallerinde ta\u015f\u0131y\u0131c\u0131 frekans hatas\u0131n\u0131n k\u00fc\u00e7\u00fck olmas\u0131, sinyalin do\u011fru bir \u015fekilde al\u0131nmas\u0131 i\u00e7in \u00f6nemlidir. 2 MHz \u00fczerindeki hatalar genellikle sinyaldeki parazit veya sapmalardan kaynaklan\u0131r ve g\u00fcvenilir veri elde edilmesini zorla\u015ft\u0131r\u0131r.\n",
    "\n",
    "- **Uydu e\u011fim a\u00e7\u0131s\u0131 (SvElevationDegrees) 10 dereceden b\u00fcy\u00fck olmal\u0131.** \u00c7\u00fcnk\u00fc, 10 derece alt\u0131ndaki a\u00e7\u0131lar veya 15 derece \u00fcst\u00fcndeki a\u00e7\u0131lar, sinyalin atmosferik etkilerden (\u00f6rne\u011fin troposferik k\u0131r\u0131lma ya da bir di\u011fer deyi\u015fle GPS uydusunun sinyalinin var\u0131\u015f\u0131ndaki gecikme) daha fazla etkilenmesine neden olabilir. Ayr\u0131ca, al\u0131c\u0131ya gelen sinyalin zay\u0131f olmas\u0131 d\u00fc\u015f\u00fck e\u011fim a\u00e7\u0131lar\u0131nda daha olas\u0131d\u0131r.\n",
    "\n",
    "- **Ta\u015f\u0131y\u0131c\u0131-g\u00fcr\u00fclt\u00fc oran\u0131 (Cn0DbHz) 15 dB-Hz'den b\u00fcy\u00fck olmal\u0131.** \u00c7\u00fcnk\u00fc, Ta\u015f\u0131y\u0131c\u0131-g\u00fcr\u00fclt\u00fc oran\u0131, sinyal kalitesini g\u00f6steren \u00f6nemli bir metriktir. 15 dB-Hz alt\u0131ndaki sinyaller zay\u0131f olarak kabul edilir ve konum belirleme do\u011frulu\u011funu olumsuz etkileyebilir.\n",
    "\n",
    "- **\u00c7oklu yol etkisi (MultipathIndicator) olmad\u0131\u011f\u0131n\u0131 belirtmeli.** \u00c7\u00fcnk\u00fc, \u00c7oklu yol etkisi, GNSS sinyallerinin y\u00fczeylerden yans\u0131mas\u0131 sonucu farkl\u0131 yollardan al\u0131c\u0131ya ula\u015fmas\u0131d\u0131r. Bu durum, sinyalin do\u011frulu\u011funu ciddi \u015fekilde bozabilir. Bu nedenle, yaln\u0131zca do\u011frudan gelen sinyaller se\u00e7ilmelidir.\n",
    "\n",
    "Bu fonksiyonu yazmam\u0131zdaki sebep, GNSS sinyallerinin do\u011frulu\u011funu art\u0131rmak ve hatal\u0131 sinyallerden kaynaklanan sapmalar\u0131 azaltmakt\u0131r."
   ],
   "metadata": {
    "id": "N5cgW7OJ2w1g"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# GNSS veri \u00e7er\u00e7evesinden uydu sinyallerini belirli kriterlere g\u00f6re filtreleyen fonksiyon\n",
    "def satellite_selection(df, column):\n",
    "    \"\"\"\n",
    "    Bu fonksiyon, GNSS veri \u00e7er\u00e7evesinden belirli kriterlere uymayan uydu sinyallerini filtreler.\n",
    "\n",
    "    Args:\n",
    "        df : DataFrame from device_gnss.csv\n",
    "            GNSS \u00f6l\u00e7\u00fcmlerini i\u00e7eren veri \u00e7er\u00e7evesi.\n",
    "        column : str\n",
    "            Sinyallerin filtrelenece\u011fi s\u00fctunun ad\u0131.\n",
    "\n",
    "    Returns:\n",
    "        df : DataFrame\n",
    "            Belirtilen kriterlere uyan uydu sinyallerini i\u00e7eren filtrelenmi\u015f veri \u00e7er\u00e7evesi geri d\u00f6nd\u00fcr\u00fclecek.\n",
    "    \"\"\"\n",
    "    # Null olmayan de\u011ferlerle \u00e7al\u0131\u015fmak i\u00e7in\n",
    "    idx = df[column].notnull()\n",
    "\n",
    "    # Ta\u015f\u0131y\u0131c\u0131 frekans hatas\u0131 (CarrierErrorHz) 2 MHz'ten k\u00fc\u00e7\u00fck olmal\u0131. \u00c7\u00fcnk\u00fc:\n",
    "    #  - GNSS sinyallerinde ta\u015f\u0131y\u0131c\u0131 frekans hatas\u0131n\u0131n k\u00fc\u00e7\u00fck olmas\u0131, sinyali do\u011fru bir \u015fekilde almam\u0131z i\u00e7in \u00f6nemlidir.\n",
    "    #  - 2 MHz \u00fczerindeki hatalar genellikle sinyaldeki parazit veya sapmalardan kaynaklan\u0131r ve g\u00fcvenilir veriyi elde etmemizi zorla\u015ft\u0131r\u0131r.\n",
    "    idx &= df['CarrierErrorHz'] < 2.0e6\n",
    "\n",
    "    # Uydu e\u011fim a\u00e7\u0131s\u0131 (SvElevationDegrees) 10 ila 15 derece aras\u0131nda olmal\u0131. \u00c7\u00fcnk\u00fc:\n",
    "    #  - 10 derece alt\u0131ndaki a\u00e7\u0131lar, sinyalin atmosferik etkilerden (\u00f6rne\u011fin troposferik k\u0131r\u0131lma - sinyaldeki gecikme) daha fazla etkilenmesine neden olabilir.\n",
    "    #  - Ayr\u0131ca,  e\u011fim a\u00e7\u0131s\u0131 d\u00fc\u015ft\u00fck\u00e7e al\u0131c\u0131ya gelen sinyalin zay\u0131flamas\u0131 daha olas\u0131d\u0131r.\n",
    "    idx &= df['SvElevationDegrees'] > 10.0\n",
    "\n",
    "    # Ta\u015f\u0131y\u0131c\u0131-g\u00fcr\u00fclt\u00fc oran\u0131 (C/N0) 15 dB-Hz'den b\u00fcy\u00fck olmal\u0131. \u00c7\u00fcnk\u00fc:\n",
    "    # - Ta\u015f\u0131y\u0131c\u0131-g\u00fcr\u00fclt\u00fc oran\u0131, sinyal kalitesini g\u00f6steren \u00f6nemli bir metriktir.\n",
    "    # - 15 dB-Hz alt\u0131ndaki sinyaller zay\u0131f olarak kabul edilir ve konum belirleme do\u011frulu\u011funu olumsuz etkileyebilir.\n",
    "    idx &= df['Cn0DbHz'] > 15.0\n",
    "\n",
    "    # \u00c7oklu yol etkisi (MultipathIndicator = 0) olmamal\u0131. \u00c7\u00fcnk\u00fc:\n",
    "    # - \u00c7oklu yol etkisi, GNSS sinyallerinin y\u00fczeylerden yans\u0131mas\u0131 sonucu farkl\u0131 yollardan al\u0131c\u0131ya ula\u015fmas\u0131d\u0131r.\n",
    "    # - Bu durum, sinyalin do\u011frulu\u011funu ciddi \u015fekilde bozabilir. Bu nedenle, yaln\u0131zca do\u011frudan gelen sinyaller se\u00e7ilmeli , y\u00fczeyden seken sinyalleri egale etmeliyiz.\n",
    "    idx &= df['MultipathIndicator'] == 0\n",
    "\n",
    "    # Belirtilen kriterlere uyan sat\u0131rlar\u0131 d\u00f6nd\u00fcr\n",
    "    return df[idx]\n"
   ],
   "metadata": {
    "id": "X6n_dVLTN453"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4- Uydu Sinyallerinden Yery\u00fcz\u00fcndeki Bir Kullan\u0131c\u0131n\u0131n Konumunu ve H\u0131z\u0131n\u0131 Hesaplama (Weighted Least Squares / A\u011f\u0131rl\u0131kl\u0131 En K\u00fc\u00e7\u00fck Kareler Y\u00f6nemi \u0130le)"
   ],
   "metadata": {
    "id": "5CFAQqrf-MBW"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "GNSS sistemlerinde al\u0131c\u0131ya gelen sinyallerin i\u00e7erdi\u011fi veriler (\u00f6rne\u011fin pseudorange) her zaman ayn\u0131 kalitede de\u011fildir. Baz\u0131 uydulardan gelen sinyaller g\u00fcr\u00fclt\u00fcl\u00fcd\u00fcr, baz\u0131lar\u0131 daha g\u00fcvenilirdir.\n",
    "\n",
    "WLS, her \u00f6l\u00e7\u00fcme e\u015fit a\u011f\u0131rl\u0131k vermek yerine, g\u00fcvenilirli\u011fi y\u00fcksek olan \u00f6l\u00e7\u00fcmlere daha fazla, d\u00fc\u015f\u00fck g\u00fcvenilirli\u011fe sahip olanlara ise daha az a\u011f\u0131rl\u0131k vererek tahmin yapar.\n",
    "\n",
    "Bu Projedeki Rol\u00fc\n",
    "Projedeki i\u015flem s\u0131ras\u0131na g\u00f6re:\n",
    "\n",
    "  - Her epoch (zaman ad\u0131m\u0131) i\u00e7in GNSS uydular\u0131ndan gelen veriler al\u0131n\u0131r.\n",
    "\n",
    "  - Bu verilerin i\u00e7inde RawPseudorangeUncertaintyMeters gibi belirsizlik \u00f6l\u00e7\u00fcmleri yer al\u0131r.\n",
    "\n",
    "  - WLS, bu belirsizlik de\u011ferlerini a\u011f\u0131rl\u0131k matrisi olarak kullan\u0131r ve konum tahmini yapar.\n",
    "\n",
    "\n",
    "\n",
    "Ayn\u0131 mant\u0131kla, h\u0131z tahmini i\u00e7in de WLS kullan\u0131l\u0131r (PseudorangeRateUncertaintyMetersPerSecond).\n",
    "\n",
    "Bu sayede:\n",
    "\n",
    "  - G\u00fcr\u00fclt\u00fcl\u00fc uydu sinyallerinin etkisi azalt\u0131l\u0131r.\n",
    "\n",
    "  - Konum ve h\u0131z tahmini daha hassas olur.\n",
    "\n",
    "  - Kalman filtresi veya LSTM gibi modellerden \u00f6nce g\u00fcvenilir ba\u015flang\u0131\u00e7 de\u011ferleri elde edilir.\n",
    "\n",
    "Sonu\u00e7 olarak bu projede WLS, GNSS verileri ile:\n",
    "\n",
    "  - \u0130lk konum ve h\u0131z tahminlerini sa\u011flamak,\n",
    "\n",
    "  - G\u00fcr\u00fclt\u00fcl\u00fc verilerin etkisini azaltmak,\n",
    "\n",
    "  - Sonraki ad\u0131mlarda kullan\u0131lacak (\u00f6rne\u011fin Kalman veya LSTM gibi) modellere sa\u011flam zemin haz\u0131rlamak i\u00e7in kritik bir rol oynar.\n",
    "\n",
    "\n",
    "\u00d6zetle:\n",
    "  -  WLS, \"ham veriden sa\u011flam tahmin\" i\u00e7in ba\u015flang\u0131\u00e7 filtresidir.\n",
    "  - Kalman, \"ak\u0131ll\u0131 d\u00fczeltici\", LSTM ise \"veriden \u00f6\u011frenen \u00f6ng\u00f6r\u00fcc\u00fc\" olarak i\u015fin devam\u0131n\u0131 getirir."
   ],
   "metadata": {
    "id": "O7gM4upGYCG0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def point_positioning(gnss_df):\n",
    "    # Her uydu (Svid) ve sinyal tipi (SignalType) i\u00e7in ta\u015f\u0131y\u0131c\u0131 frekans\u0131 (CarrierFrequencyHz) s\u00fctunundaki medyan de\u011ferleri hesapl\u0131yoruz.\n",
    "    CarrierFrequencyHzRef = gnss_df.groupby(['Svid', 'SignalType'])['CarrierFrequencyHz'].median()\n",
    "    # Yukar\u0131da olu\u015ftrudu\u011fumuz her medyan de\u011ferini, orijinal GNSS verileriyle birle\u015ftirdik\n",
    "    gnss_df = gnss_df.merge(CarrierFrequencyHzRef, how='left', on=['Svid', 'SignalType'], suffixes=('', 'Ref'))\n",
    "\n",
    "    # \u00dcstte Hesaplad\u0131\u011f\u0131m CarrierFrequencyHzRef ile veri setinde bulunan CarrierFrequencyHz aras\u0131ndaki fark\u0131 bularak ta\u015f\u0131y\u0131c\u0131 frekans\u0131 hatas\u0131n\u0131 (CarrierErrorHz) hesaplad\u0131k ...\n",
    "    # ... ve veri setimizde 'CarrierErrorHz' s\u00fctununu ekledik\n",
    "    # \u00c7\u00fcnk\u00fc ba\u015flarda da bahsetti\u011fimiz gibi Ta\u015f\u0131y\u0131c\u0131 frekans hatas\u0131 (CarrierErrorHz) 2 MHz'ten k\u00fc\u00e7\u00fck olursa i\u015fimize yarayacak\n",
    "    gnss_df['CarrierErrorHz'] = np.abs((gnss_df['CarrierFrequencyHz'] - gnss_df['CarrierFrequencyHzRef']))\n",
    "\n",
    "    # Pseudorange verisini (ger\u00e7ek mesafe \u00f6l\u00e7\u00fcm\u00fcnden elde edilen de\u011fer) Carrier Smoothing (ta\u015f\u0131y\u0131c\u0131-p\u00fcr\u00fczs\u00fczle\u015ftirme) y\u00f6ntemiyle d\u00fczg\u00fcnle\u015ftirdik.\n",
    "    # Basit\u00e7e Carrier Smoothing: pseudorange verisinin do\u011frulu\u011funu art\u0131rmak i\u00e7in kullan\u0131lan bir tekniktir. Verilerdeki g\u00fcr\u00fclt\u00fcy\u00fc azalt\u0131r ve daha do\u011fru yer belirleme (positioning) sa\u011flar\n",
    "    gnss_df = carrier_smoothing(gnss_df)\n",
    "\n",
    "    # Benzersiz zaman damgalar\u0131n\u0131 alacak ve toplam iterasyon say\u0131s\u0131n\u0131 hesaplayaca\u011f\u0131z. Yani, ka\u00e7 farkl\u0131 zaman noktas\u0131n\u0131n (epoch) veri setinde bulundu\u011funu g\u00f6sterece\u011fiz\n",
    "    utcTimeMillis = gnss_df['utcTimeMillis'].unique() # \"utcTimeMillis\", her bir veri kayd\u0131n\u0131n zaman\u0131n\u0131 milisaniye cinsinden temsil ediyor.\n",
    "    nepoch = len(utcTimeMillis)  # Toplam iterasyon say\u0131s\u0131\n",
    "\n",
    "    # Pozisyon ve h\u0131z i\u00e7in ba\u015flang\u0131\u00e7 vekt\u00f6rlerini tan\u0131mlad\u0131k\n",
    "    x0 = np.zeros(4)  # Ba\u015flang\u0131\u00e7 pozisyon [x, y, z, saat] -> her birine ilk de\u011fer olarak 0 atad\u0131k\n",
    "    v0 = np.zeros(4)  # Ba\u015flang\u0131\u00e7 h\u0131z [vx, vy, vz, saat] -> her birine ilk de\u011fer olarak 0 atad\u0131k\n",
    "\n",
    "    # Pozisyon ve h\u0131z tahminlerini kay\u0131t etmek i\u00e7in matrisler olu\u015fturaca\u011f\u0131z\n",
    "    x_wls = np.full([nepoch, 3], np.nan)  # Pozisyon tahminlerini kaydetmek i\u00e7in\n",
    "    v_wls = np.full([nepoch, 3], np.nan)  # H\u0131z tahminlerini kaydetmek i\u00e7in\n",
    "\n",
    "\n",
    "    for i, (t_utc, df) in enumerate(tqdm(gnss_df.groupby('utcTimeMillis'), total=nepoch)):\n",
    "        # Ge\u00e7erli uydu sinyallerini Pseudorange verisi i\u00e7in se\u00e7elim\n",
    "        df_pr = satellite_selection(df, 'pr_smooth')\n",
    "        # Ge\u00e7erli uydu sinyallerini Pseudorange Rate verisi i\u00e7in se\u00e7elim\n",
    "        df_prr = satellite_selection(df, 'PseudorangeRateMetersPerSecond')  # PseudorangeRateMetersPerSecond, pseudorange'nin zamanla de\u011fi\u015fme h\u0131z\u0131n\u0131 (yani, al\u0131c\u0131 ile uydu aras\u0131ndaki mesafenin h\u0131z\u0131n\u0131) ifade eder.\n",
    "\n",
    "        # GNSS verisindeki pseudorange hatalar\u0131n\u0131 d\u00fczeltmek i\u00e7in gerekli d\u00fczenlemeler yapaca\u011f\u0131z:\n",
    "        # - SvClockBiasMeters: Uydu saatinin yanl\u0131\u015f\u0131 (saat kaymas\u0131)\n",
    "        # - IsrbMeters:  uydunun yer\u00e7ekimi, ortam ko\u015fullar\u0131 veya di\u011fer etmenler nedeniyle olu\u015fan k\u00fc\u00e7\u00fck sapmalar\u0131 ifade eder\n",
    "        # - IonosphericDelayMeters (\u0130yonosferik Gecikme): GNSS sinyalleri, iyonosferdeki serbest elektron yo\u011funlu\u011fu nedeniyle h\u0131z kayb\u0131na u\u011frar.\n",
    "        # - TroposphericDelayMeters (Troposferik Gecikme): Troposferdeki nem, s\u0131cakl\u0131k ve bas\u0131n\u00e7 fakt\u00f6rler,, GNSS sinyallerini etkileyebilir ve bu da sinyallerin al\u0131c\u0131ya ula\u015fma s\u00fcresini uzat\u0131r.\n",
    "        pr = (df_pr['pr_smooth'] + df_pr['SvClockBiasMeters'] - df_pr['IsrbMeters'] - df_pr['IonosphericDelayMeters'] - df_pr['TroposphericDelayMeters']).to_numpy()\n",
    "\n",
    "        # Pseudorange Rate (Pseudorange H\u0131z\u0131) ve SvClock Drift (Uydu Saat Kaymas\u0131) verilerini birle\u015ftirilerek, d\u00fczeltilmi\u015f Pseudorange Rate elde edece\u011fiz.\n",
    "        prr = (df_prr['PseudorangeRateMetersPerSecond'] + df_prr['SvClockDriftMetersPerSecond']).to_numpy()\n",
    "\n",
    "        # Uydu pozisyon verilerini Pseudorange verisi i\u00e7in alaca\u011f\u0131z:\n",
    "        #  - ECEF (Earth-Centered, Earth-Fixed): D\u00fcnya merkezine dayal\u0131 bir koordinat sistemidir.\n",
    "        xsat_pr = df_pr[['SvPositionXEcefMeters', 'SvPositionYEcefMeters','SvPositionZEcefMeters']].to_numpy()\n",
    "\n",
    "        # Uydu pozisyon verilerini Pseudorange Rate verisi i\u00e7in h\u0131z i\u00e7in alaca\u011f\u0131z\n",
    "        xsat_prr = df_prr[['SvPositionXEcefMeters', 'SvPositionYEcefMeters','SvPositionZEcefMeters']].to_numpy()\n",
    "\n",
    "        # Uydu h\u0131z verilerini Pseudorange Rate verisi i\u00e7in alaca\u011f\u0131z\n",
    "        vsat = df_prr[['SvVelocityXEcefMetersPerSecond', 'SvVelocityYEcefMetersPerSecond','SvVelocityZEcefMetersPerSecond']].to_numpy()\n",
    "\n",
    "        # Pseudorange ve Pseudorange Rate i\u00e7in a\u011f\u0131rl\u0131k matrislerini hesaplayaca\u011f\u0131z\n",
    "        # Buradaki \"1 / df_pr['RawPseudorangeUncertaintyMeters']\" i\u015flemi:\n",
    "        # Her bir belirsizli\u011fin tersini al\u0131r. Belirsizli\u011fin tersten al\u0131nmas\u0131, daha d\u00fc\u015f\u00fck belirsizli\u011fe sahip \u00f6l\u00e7\u00fcmlere daha fazla a\u011f\u0131rl\u0131k verir...\n",
    "        # ... Y\u00fcksek belirsizlik, d\u00fc\u015f\u00fck a\u011f\u0131rl\u0131k anlam\u0131na gelir. Yani, g\u00fcvenilir olmayan \u00f6l\u00e7\u00fcmler daha d\u00fc\u015f\u00fck bir a\u011f\u0131rl\u0131\u011fa sahip olmal\u0131.\n",
    "        Wx = np.diag(1 / df_pr['RawPseudorangeUncertaintyMeters'].to_numpy())\n",
    "        Wv = np.diag(1 / df_prr['PseudorangeRateUncertaintyMetersPerSecond'].to_numpy())\n",
    "\n",
    "\n",
    "        # Art\u0131k kullan\u0131c\u0131n\u0131n POZ\u0130SYON TAHM\u0130N\u0130N\u0130 yapabiliriz\n",
    "\n",
    "        if len(df_pr) >= 4:  # Konumu do\u011fru belirleyebilmek i\u00e7in en az 4 uydu gerekir -> 3D konum + zaman\n",
    "            if np.all(x0 == 0):  # Ba\u015flang\u0131\u00e7 tahmini 0 ise\n",
    "                # Bu k\u0131s\u0131mda, LEAST SQUARES (en k\u00fc\u00e7\u00fck kareler) y\u00f6ntemi kullan\u0131larak pozisyon tahmini yapaca\u011f\u0131z:\n",
    "                # - pr_residuals: Bu fonksiyon, modelle uydu \u00f6l\u00e7\u00fcmleri aras\u0131ndaki farklar\u0131 hesaplayacak. (residuals = art\u0131k)\n",
    "                # - jac_pr_residuals: \u00f6l\u00e7\u00fcm hatalar\u0131n\u0131n (residul) t\u00fcrevini alarak do\u011frusal olmayan optimizasyonun yap\u0131lmas\u0131n\u0131 sa\u011flar.\n",
    "                # - xsat_pr: Uydular\u0131n konum verilerini i\u00e7eren NumPy dizisi.\n",
    "                # - pr: Pseudorange (mesafe \u00f6l\u00e7\u00fcm) verileri.\n",
    "                # - Wx: Pseudorange belirsizliklerine dayal\u0131 a\u011f\u0131rl\u0131k matrisi.\n",
    "                opt = scipy.optimize.least_squares(pr_residuals, x0, jac_pr_residuals, args=(xsat_pr, pr, Wx))\n",
    "\n",
    "                # Daha sonra yukar\u0131da optimize edilen pozisyonu g\u00fcncel pozisyonumuz olarak g\u00fcncelledik\n",
    "                x0 = opt.x\n",
    "\n",
    "            # Normal WLS'ten sonra Robust (dayan\u0131kl\u0131) WLS ile pozisyon tahmini yaparak \u00f6l\u00e7\u00fcm do\u011frulu\u011funu artt\u0131raca\u011f\u0131z:\n",
    "            # Burada\" soft_l1\" loss fonksiyonu kullan\u0131larak, pozisyon tahmini yap\u0131l\u0131rken daha az g\u00fcvenilir \u00f6l\u00e7\u00fcmlerin etkisi azalt\u0131lmak istiyoruz.\n",
    "            opt = scipy.optimize.least_squares(pr_residuals, x0, jac_pr_residuals, args=(xsat_pr, pr, Wx), loss='soft_l1')\n",
    "\n",
    "\n",
    "            # Optimizasyonun durumunu kontrol ederek ba\u015far\u0131l\u0131 m\u0131 ba\u015far\u0131s\u0131z m\u0131 diye bakal\u0131m\n",
    "            # - (0) = Ba\u015far\u0131l\u0131 optimizasyon\n",
    "            # - (1) = Ba\u015far\u0131yla tamamlanm\u0131\u015f ancak istenen hassasiyete ula\u015f\u0131lmam\u0131\u015f.\n",
    "            # - (2) = Optimizasyon ba\u015far\u0131yla tamamlanm\u0131\u015f ancak maksimum iterasyon say\u0131s\u0131na ula\u015f\u0131lm\u0131\u015f. Yani, \u00e7\u00f6z\u00fcme ula\u015fmak i\u00e7in daha fazla iterasyon yap\u0131labilirdi ancak durdurulmu\u015f.\n",
    "            # - (-1): Ba\u015far\u0131s\u0131zl\u0131k, optimizasyonun \u00e7\u00f6z\u00fcme ula\u015famad\u0131\u011f\u0131 durum.\n",
    "            # - (-2): Ba\u015far\u0131s\u0131zl\u0131k.\n",
    "            if opt.status < 1 or opt.status == 2:\n",
    "                print(f'i = {i} KONUM optimizasyon durumu = {opt.status}')\n",
    "\n",
    "            else:\n",
    "              # E\u011fer optimizasyon ba\u015far\u0131l\u0131 bir \u015fekilde tamamlanm\u0131\u015fsa, tahmin edilen pozisyon (opt.x) al\u0131n\u0131r ve x_wls'ye kaydedilir.\n",
    "              # Buradaki opt.x[:3] k\u0131sm\u0131, elde edilen 4 elemanl\u0131 \u00e7\u00f6z\u00fcm vekt\u00f6r\u00fcn\u00fcn (3D + Zaman) ilk 3 eleman\u0131n\u0131 (x, y, z koordinatlar\u0131n\u0131) al\u0131r.\n",
    "                x_wls[i, :] = opt.x[:3]  # Tahmin edilen pozisyonu kaydet\n",
    "                x0 = opt.x  # Pozisyonu g\u00fcncelle\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Kullan\u0131c\u0131n\u0131n HIZ TAHM\u0130N\u0130N\u0130 de yapabliriz\n",
    "\n",
    "        # \u00dcstte konum i\u00e7in yapt\u0131\u011f\u0131m\u0131z t\u00fcm i\u015flemlerin ayn\u0131s\u0131n\u0131 h\u0131z i\u00e7in de yapaca\u011f\u0131z\n",
    "        if len(df_prr) >= 4:  # En az 4 uydu verisi gerekli demi\u015ftik\n",
    "            if np.all(v0 == 0):  # Ba\u015flang\u0131\u00e7 tahmini yoksa normal WLS ile ba\u015fla\n",
    "                opt = scipy.optimize.least_squares(prr_residuals, v0, jac_prr_residuals, args=(vsat, prr, x0, xsat_prr, Wv))\n",
    "                v0 = opt.x  # Optimize edilen h\u0131z\u0131 g\u00fcncelledik\n",
    "            # Robust (Dayan\u0131kl\u0131) WLS ile h\u0131z tahmini yapt\u0131k\n",
    "            opt = scipy.optimize.least_squares(prr_residuals, v0, jac_prr_residuals, args=(vsat, prr, x0, xsat_prr, Wv), loss='soft_l1')\n",
    "            if opt.status < 1:  # Y\u0130ne optimizaston durumlar\u0131n\u0131 kontrol edece\u011fiz\n",
    "                print(f'i = {i} HIZ optimizasyon durumu = {opt.status}')\n",
    "            else:\n",
    "                v_wls[i, :] = opt.x[:3]  # Tahmin edilen h\u0131z\u0131 kaydet\n",
    "                v0 = opt.x  # H\u0131z\u0131 g\u00fcncelle\n",
    "\n",
    "    # Tahmin edilen zaman, pozisyon ve h\u0131z de\u011ferlerini d\u00f6nd\u00fcr\n",
    "    return utcTimeMillis, x_wls, v_wls\n"
   ],
   "metadata": {
    "id": "ePKh_QX6N-eX"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 5- Carrier Smoothing (Ta\u015f\u0131y\u0131c\u0131 P\u00fcr\u00fczs\u00fczle\u015ftirme) ile Pseudorange (Ger\u00e7ek Mesafa , Konum/H\u0131z Tahmini) Tahmininin Do\u011frulu\u011funu Art\u0131rma\n",
    "\n",
    "Bu fonksiyon, GNSS verilerinde ta\u015f\u0131y\u0131c\u0131-faz ve pseudorange \u00f6l\u00e7\u00fcmlerini birle\u015ftirerek ta\u015f\u0131y\u0131c\u0131 p\u00fcr\u00fczs\u00fczle\u015ftirme (carrier smoothing) y\u00f6ntemiyle daha hassas bir pseudorange tahmini yapar. Bu i\u015flem, sinyal hatalar\u0131n\u0131 ve sapmalar\u0131 azaltmay\u0131 hedefler.\n",
    "\n",
    "Pseudorange tahmini, GNSS (Global Navigation Satellite System) verilerinden kullan\u0131c\u0131 konumunu ve h\u0131z\u0131n\u0131 belirlemek i\u00e7in temel bir girdidir. Bu tahminler, uydu ile al\u0131c\u0131 aras\u0131ndaki \u00f6l\u00e7\u00fclen mesafeyi temsil eder, ancak bu mesafeler \u00e7e\u015fitli hatalardan (\u00f6rne\u011fin, iyonosferik ve troposferik gecikmeler, saat hatalar\u0131) etkilenir. **Carrier smoothing, bu hatalar\u0131 azaltarak daha g\u00fcvenilir bir pseudorange tahmini sa\u011flar.**"
   ],
   "metadata": {
    "id": "RapYOYOgFr-j"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def carrier_smoothing(gnss_df):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        df:'pr_smooth' ad\u0131nda ta\u015f\u0131y\u0131c\u0131 p\u00fcr\u00fczs\u00fczle\u015ftirilmi\u015f pseudorange DataFram'i\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # E\u015fik De\u011ferlerimizi tan\u0131mlayal\u0131m:\n",
    "\n",
    "      # Ta\u015f\u0131y\u0131c\u0131 faz s\u0131\u00e7rama e\u015fi\u011fi [metre].\n",
    "      # Bu de\u011fer, ta\u015f\u0131y\u0131c\u0131 faz \u00f6l\u00e7\u00fcmlerindeki ani s\u0131\u00e7ramalar\u0131n (cycle slip) tolerans s\u0131n\u0131r\u0131n\u0131 belirler.\n",
    "    carr_th = 1.6\n",
    "\n",
    "      # Pseudorange s\u0131\u00e7rama e\u015fi\u011fi [metre].\n",
    "      # Bu de\u011fer, pseudorange \u00f6l\u00e7\u00fcmlerinde ani de\u011fi\u015fimlerin hata olarak alg\u0131lanmas\u0131 i\u00e7in s\u0131n\u0131r belirler.\n",
    "    pr_th =  20.0\n",
    "\n",
    "\n",
    "\n",
    "    # pseudorange de\u011ferlerini ta\u015f\u0131y\u0131c\u0131-p\u00fcr\u00fczs\u00fczle\u015ftirme (carrier smoothing) i\u015flemi sonras\u0131 saklayacak bir dizi olu\u015fturduk\n",
    "    prsmooth = np.full_like(gnss_df['RawPseudorangeMeters'], np.nan)  # np.nan ile birlikte p\u00fcr\u00fczs\u00fczle\u015ftirme i\u015flemi sonras\u0131 de\u011ferleri yer de\u011fi\u015ftirece\u011fiz\n",
    "\n",
    "\n",
    "    # Her bir sinyal i\u00e7in ta\u015f\u0131y\u0131c\u0131-p\u00fcr\u00fczs\u00fczle\u015ftirme (carrier smoothing) i\u015flemini ger\u00e7ekle\u015ftirece\u011fiz:\n",
    "    for (i, (svid_sigtype, df)) in enumerate((gnss_df.groupby(['Svid', 'SignalType']))):\n",
    "\n",
    "        # 'AccumulatedDeltaRangeMeters' (Birikmi\u015f Delta Menzil \u00d6l\u00e7erler) s\u00fctunundaki 0 de\u011ferlerini NaN (ge\u00e7ersiz) ile de\u011fi\u015ftiriyoruz...\n",
    "        # ... B\u00f6ylece hatal\u0131 verilerin i\u015flemi etkilemesini engelleyece\u011fiz.\n",
    "        df = df.replace({'AccumulatedDeltaRangeMeters': {0: np.nan}})\n",
    "\n",
    "\n",
    "        # Doppler h\u0131z bilgisiyle pseudorange (drng2) ve ta\u015f\u0131y\u0131c\u0131 faz (drng1) de\u011fi\u015fimlerini kar\u015f\u0131la\u015ft\u0131raca\u011f\u0131z...\n",
    "        # ... B\u00f6ylece, d\u00f6ng\u00fc kaymalar\u0131 (cycle-slip) gibi hatalar\u0131 tespit edece\u011fiz.\n",
    "        drng1 = df['AccumulatedDeltaRangeMeters'].diff() - df['PseudorangeRateMetersPerSecond']\n",
    "        drng2 = df['RawPseudorangeMeters'].diff() - df['PseudorangeRateMetersPerSecond']\n",
    "\n",
    "\n",
    "        # Farkl\u0131 durumlara g\u00f6re d\u00f6ng\u00fc kaymas\u0131 (cycle-slip) hatalar\u0131n\u0131 kontrol etmeliyiz. Yani 'hata t\u00fcrlerini' belirlemeliyiz:\n",
    "          # - slip3: Ta\u015f\u0131y\u0131c\u0131 faz de\u011fi\u015fimi belirledi\u011fimiz e\u015fik de\u011ferini (carr_th) a\u015farsa hata olarak i\u015faretlenecek.\n",
    "          # - slip4: Pseudorange de\u011fi\u015fimi belirledi\u011fimiz e\u015fik de\u011ferini (pr_th) a\u015farsa hata olarak i\u015faretlenecek.\n",
    "        slip1 = (df['AccumulatedDeltaRangeState'].to_numpy() & 2**1) != 0  # s\u0131f\u0131rlama bayra\u011f\u0131\n",
    "        slip2 = (df['AccumulatedDeltaRangeState'].to_numpy() & 2**2) != 0  # d\u00f6ng\u00fc kayma bayra\u011f\u0131\n",
    "        slip3 = np.fabs(drng1.to_numpy()) > carr_th\n",
    "        slip4 = np.fabs(drng2.to_numpy()) > pr_th\n",
    "\n",
    "\n",
    "        # \u00dcstte olu\u015fturdu\u011fumuz d\u00f6ng\u00fc hata t\u00fcrlerini buldu\u011fumuzda bunlar\u0131 i\u015faretleyece\u011fiz:\n",
    "        idx_slip = slip1 | slip2 | slip3 | slip4 # Herhangi bir d\u00f6ng\u00fc kaymas\u0131 durumu 'True' olarak i\u015faretlenecek. Bunun i\u00e7in \u00fcstte belirledi\u011fimiz hata t\u00fcrlerini bir de\u011fi\u015fkende tuttuk.\n",
    "        # \u0130lk veri noktas\u0131n\u0131 True olarak i\u015faretleyece\u011fiz. \u00c7\u00fcnk\u00fc ilk veri noktas\u0131ndan \u00f6nce bir veri olmad\u0131\u011f\u0131 i\u00e7in d\u00f6ng\u00fc kaymas\u0131 i\u00e7eriyor gini de\u011ferlendirdik.\n",
    "        idx_slip[0] = True\n",
    "\n",
    "\n",
    "\n",
    "        # S\u00fcrekli ta\u015f\u0131y\u0131c\u0131 faz izleme gruplar\u0131n\u0131 olu\u015ftur\n",
    "        df['group_slip'] = np.cumsum(idx_slip)  # Her d\u00f6ng\u00fc kaymas\u0131 tespit edildi\u011finde grup numaras\u0131 bir art\u0131r\u0131l\u0131r.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # Pseudorange (ham mesafe \u00f6l\u00e7\u00fcm\u00fc) ile ta\u015f\u0131y\u0131c\u0131 faz \u00f6l\u00e7\u00fcm\u00fc aras\u0131ndaki fark\u0131 hesaplad\u0131k\n",
    "        # Bu fark [dpc], \u00f6l\u00e7\u00fcm hatalar\u0131n\u0131n analizinde ve ta\u015f\u0131y\u0131c\u0131 faz \u00f6l\u00e7\u00fcmlerine dayal\u0131 do\u011frulu\u011fun art\u0131r\u0131lmas\u0131nda \u00f6nemli bir rol oynayacak\n",
    "        df['dpc'] = df['RawPseudorangeMeters'] - df['AccumulatedDeltaRangeMeters']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # \u00dcstte olu\u015fturdu\u011fumuz group_slip'e g\u00f6re her gruptaki dpc(Psudorange - carrier phase) de\u011ferlerinin  ortalamas\u0131n\u0131 hesaplad\u0131k\n",
    "        meandpc = df.groupby('group_slip')['dpc'].mean()\n",
    "        df = df.merge(meandpc, on='group_slip', suffixes=('', '_Mean')) # Bu ortalamalar\u0131 df'e ekledik\n",
    "\n",
    "\n",
    "\n",
    "        # Hata i\u00e7eren uydu id'lerini ve sinyal tiplerini orijinal gnns_df'te buluyoruz\n",
    "        idx = (gnss_df['Svid'] == svid_sigtype[0]) & (gnss_df['SignalType'] == svid_sigtype[1])\n",
    "\n",
    "\n",
    "\n",
    "        # Bu gata i\u00e7eeren uydulara ta\u015f\u0131y\u0131c\u0131 faz \u00f6l\u00e7\u00fcm\u00fc ve bias'\u0131 ekleyerek d\u00fczg\u00fcnle\u015ftirilmi\u015f pseudorange'\u0131 hesapl\u0131yoruz\n",
    "        prsmooth[idx] = df['AccumulatedDeltaRangeMeters'] + df['dpc_Mean']\n",
    "\n",
    "\n",
    "\n",
    "    # E\u011fer ta\u015f\u0131y\u0131c\u0131-p\u00fcr\u00fczs\u00fczle\u015ftirme m\u00fcmk\u00fcn de\u011filse, orijinal pseudorange de\u011ferini kullanaca\u011f\u0131z:\n",
    "    idx_nan = np.isnan(prsmooth) # NaN de\u011ferlerini bul\n",
    "    prsmooth[idx_nan] = gnss_df['RawPseudorangeMeters'][idx_nan]  # NaN olan yerlerde orijinal pseudorange'\u0131 kullan\n",
    "    gnss_df['pr_smooth'] = prsmooth # Sonu\u00e7lar\u0131 'pr_smooth' s\u00fctununa ata\n",
    "\n",
    "    return gnss_df"
   ],
   "metadata": {
    "id": "v_9WUFu3OCi8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6- Pozisyon Tahmin ve Art\u0131kl\u0131k Hesaplamalar\u0131 (Ps\u00f6dorange/Doppler Kal\u0131nt\u0131lar\u0131 ve Jacobian Matrisi)\n",
    "Bu k\u0131s\u0131mda yazaca\u011f\u0131m\u0131z 5 fonksiyon kullan\u0131c\u0131 ve uydu aras\u0131ndaki pozisyon, h\u0131z ve di\u011fer etkenleri dikkate alarak GNSS verilerinden do\u011frulu\u011fu art\u0131ran hesaplamalar yapacakt\u0131r.\n",
    "\n",
    "Residuals = Kal\u0131nt\u0131 , Art\u0131k , Sapma\n",
    "<br></br>\n",
    "\n",
    "**Sagnac Etkisi Nedir?**\n",
    "\n",
    "Sagnac Etkisi, d\u00fcnyan\u0131n d\u00f6nmesi nedeniyle \u0131\u015f\u0131\u011f\u0131n h\u0131z\u0131nda k\u00fc\u00e7\u00fck bir fark olu\u015fmas\u0131d\u0131r. Bunu anlamak i\u00e7in basit bir \u00f6rnek d\u00fc\u015f\u00fcnelim:\n",
    "\n",
    "Bir d\u00f6nen atl\u0131 kar\u0131ncaya bindik ve elimizde bir el feneri var. E\u011fer feneri atl\u0131 kar\u0131ncan\u0131n d\u00f6n\u00fc\u015f y\u00f6n\u00fcnde tutarsak, \u0131\u015f\u0131\u011f\u0131n hedefe ula\u015fmas\u0131 biraz daha uzun s\u00fcrebilir. Ama ters y\u00f6nde tutarsak, \u0131\u015f\u0131k daha h\u0131zl\u0131 ula\u015f\u0131r. \u0130\u015fte bu k\u00fc\u00e7\u00fck zaman fark\u0131 Sagnac Etkisidir.\n",
    "\n",
    "Bu etki, hassas \u00f6l\u00e7\u00fcmler yapan cihazlarda fark edilir ve \u00f6zellikle GPS sistemleri ve jiroskoplarda dikkate al\u0131n\u0131r. E\u011fer d\u00fczeltilmezse, navigasyon sistemleri birka\u00e7 metre hata yapabilir. Bu y\u00fczden m\u00fchendisler, D\u00fcnya'n\u0131n d\u00f6n\u00fc\u015f\u00fcnden kaynaklanan bu etkiyi hesaba katarak sistemleri tasarlar."
   ],
   "metadata": {
    "id": "5FdxcNCeFszu"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# los_vector(xusr, xsat) fonksiyonu, kullan\u0131c\u0131 (xusr) ile uydu (xsat) aras\u0131ndaki do\u011frultu vekt\u00f6r\u00fcn\u00fc (line-of-sight vector) ve mesafeyi hesaplayacak.\n",
    "# GNSS konumland\u0131rma sistemlerinde temel bir fonksiyondur \u00e7\u00fcnk\u00fc do\u011fru bir pozisyon tahmini i\u00e7in do\u011frultu ve mesafe bilgisi gereklidir.\n",
    "def los_vector(xusr, xsat):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        xusr : ECEF'teki kullan\u0131c\u0131 konumu (m) (ECEF = Earth Centered Earth Fixed Koordinat Sistemi)\n",
    "        xsat : ECEF'teki uydu konumu (m)\n",
    "    Returns:\n",
    "        u: ECEF'teki kullan\u0131c\u0131dan uyduya do\u011fru olan birim do\u011frultu vekt\u00f6r\u00fc (unit line-of-sight)  (m)\n",
    "        rng: Kullan\u0131c\u0131 ve uydu aras\u0131ndaki mesafe (m)\n",
    "    \"\"\"\n",
    "    u = xsat - xusr # do\u011frultunun y\u00f6n\u00fc\n",
    "    rng = np.linalg.norm(u, axis=1).reshape(-1, 1)  # Kullan\u0131c\u0131 ve uydu aras\u0131ndaki mesafe\n",
    "    u /= rng\n",
    "\n",
    "    return u, rng.reshape(-1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Jacobian matrisini hesaplayan fonksiyonumuz\n",
    "# Bu matris, konum tahmin hatalar\u0131n\u0131 minimize etmek i\u00e7in kullan\u0131lan bir optimizasyon y\u00f6ntemi.\n",
    "def jac_pr_residuals(x, xsat, pr, W):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : ECEF'teki mevcut pozisyon (m)\n",
    "        xsat : ECEF'te uydu pozisyonu (m)\n",
    "        pr : pseudorange (m)\n",
    "        W : a\u011f\u0131rl\u0131k matrisi\n",
    "    Returns:\n",
    "        W*J : Jacobian matrisi\n",
    "    \"\"\"\n",
    "    u, _ = los_vector(x[:3], xsat) # Kullan\u0131c\u0131 ve uydu aras\u0131ndaki do\u011frultu vekt\u00f6r\u00fcn\u00fc hesaplayacak. Buradaki 'u, _' i\u015flemi =  (paketten \u00e7\u0131karma) \u00f6zelli\u011fidir. Fonksiyondan d\u00f6nen birden fazla de\u011feri birden fazla de\u011fi\u015fkene atamak i\u00e7in kullan\u0131l\u0131r.\n",
    "                                   # Kullan\u0131c\u0131n\u0131n ilk 3 koordinat\u0131n\u0131 alacak\n",
    "    J = np.hstack([-u, np.ones([len(pr), 1])])   # Jacobian matrisi: [-ux -uy -uz 1]\n",
    "\n",
    "    return W @ J  # A\u011f\u0131rl\u0131kl\u0131 Jacobian matrisi, yani W ile \u00e7arp\u0131lm\u0131\u015f J matrisini bize d\u00f6nd\u00fcrecek\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pseudorange art\u0131klar\u0131n\u0131 hesaplayan fonksiyonumuz.\n",
    "# Yani, kullan\u0131c\u0131 pozisyonu ile uydu aras\u0131ndaki mesafe fark\u0131 ile \u00f6l\u00e7\u00fclen pseudorange (ger\u00e7ek mesafe) aras\u0131ndaki fark\n",
    "def pr_residuals(x, xsat, pr, W):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x : kullan\u0131c\u0131n\u0131n ECEF'teki mevcut pozisyon (m)\n",
    "        xsat : ECEF'te uydu pozisyonu (m)\n",
    "        pr : pseudorange (m)\n",
    "        W : a\u011f\u0131rl\u0131k matrisi\n",
    "    Returns:\n",
    "        residuals*W : pseudorange hatalar\u0131 , art\u0131klar\u0131\n",
    "    \"\"\"\n",
    "    u, rng = los_vector(x[:3], xsat)  # \u00dcstte yazd\u0131\u011f\u0131m\u0131uz los_vector fonksiyonu \u00e7a\u011f\u0131rarak  kullan\u0131c\u0131 ile uydu aras\u0131ndaki do\u011frultu vekt\u00f6r\u00fcn\u00fc (u) ve mesafeyi (rng) hesapl\u0131yoruz.\n",
    "\n",
    "    # ! Mesafeyi hesaplarken D\u00fcnya'n\u0131n d\u00f6n\u00fc\u015f\u00fcnden kaynaklanan 'Sagnac Etkisi'ni dikkate almal\u0131y\u0131z.\n",
    "    # Burada, OMGE D\u00fcnya'n\u0131n a\u00e7\u0131sal h\u0131z\u0131 (radyan/saniye) ve CLIGHT \u0131\u015f\u0131k h\u0131z\u0131 (metre/saniye) sabitlerini kullan\u0131larak bir d\u00fczeltme uygulad\u0131k.\n",
    "    rng += OMGE * (xsat[:, 0] * x[1] - xsat[:, 1] * x[0]) / CLIGHT\n",
    "\n",
    "    # Add GPS L1 clock offset\n",
    "    residuals = rng - (pr - x[3]) # Ger\u00e7ek mesafe ile \u00f6l\u00e7\u00fclen pseudorange aras\u0131ndaki fark yani art\u0131k\n",
    "                                  # 'rng': Hesaplanan ger\u00e7ek mesafe , 'pr - x[3]': \u00d6l\u00e7\u00fclen pseudorange de\u011feri.\n",
    "                                  # x[3] = zaman bile\u015fenini temsil ediyor (x,y,z ve zaman'dan zaman'\u0131 ald\u0131k)\n",
    "\n",
    "    return residuals @ W   # Art\u0131klar\u0131 a\u011f\u0131rl\u0131k matrisi ile \u00e7arp\u0131p bize geri d\u00f6nd\u00fcrecek\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Bu fonksiyon,  kullan\u0131c\u0131n\u0131n ve uydunun h\u0131zlar\u0131 ve pozisyonlar\u0131na dayanarak pseudorange rate (PRR)'i i\u00e7in Jacobian matrisini hesaplayacak.\n",
    "# Bu da pozisyon ve h\u0131z tahmininin do\u011frulu\u011funu optimize etmekte kullan\u0131lacak\n",
    "def jac_prr_residuals(v, vsat, prr, x, xsat, W):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        v : Kullan\u0131c\u0131n\u0131n mevcut h\u0131z\u0131, ECEF koordinat sisteminde (m/s).\n",
    "        vsat : Uydu h\u0131z\u0131, ECEF koordinat sisteminde (m/s).\n",
    "        prr : Pseudorange rate (m/s), uydu ile kullan\u0131c\u0131 aras\u0131ndaki mesafe de\u011fi\u015fim h\u0131z\u0131d\u0131r.\n",
    "        x : Kullan\u0131c\u0131n\u0131n mevcut pozisyonu, ECEF koordinat sisteminde (m).\n",
    "        xsat : Uydunun pozisyonu, ECEF koordinat sisteminde (m).\n",
    "        W : A\u011f\u0131rl\u0131k matrisi\n",
    "    Returns:\n",
    "        W*J : Jacobian matrisi\n",
    "    \"\"\"\n",
    "    u, _ = los_vector(x[:3], xsat) # 2. fonksitonda da yapt\u0131\u011f\u0131m\u0131z kullan\u0131c\u0131 ve uydu aras\u0131ndaki do\u011frultu vekt\u00f6r\u00fcn\u00fc hesaplayan i\u015flem.\n",
    "    J = np.hstack([-u, np.ones([len(prr), 1])])  # Jacobian matrisi [-ux -uy -uz 1] \u015feklinde olmal\u0131\n",
    "\n",
    "    return np.dot(W, J)  # W matrisi ile J matrisini \u00e7arp\u0131m\u0131n\u0131 bize d\u00f6nd\u00fcr\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Pseudorange rate art\u0131klar\u0131n\u0131 hesaplyaca\u011f\u0131z\n",
    "def prr_residuals(v, vsat, prr, x, xsat, W):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        v : Kullan\u0131c\u0131n\u0131n mevcut h\u0131z\u0131, ECEF koordinat sisteminde (m/s).\n",
    "        vsat : Uydu h\u0131z\u0131, ECEF koordinat sisteminde (m/s).\n",
    "        prr : Pseudorange rate (m/s), uydu ile kullan\u0131c\u0131 aras\u0131ndaki mesafe de\u011fi\u015fim h\u0131z\u0131d\u0131r.\n",
    "        x : Kullan\u0131c\u0131n\u0131n mevcut pozisyonu, ECEF koordinat sisteminde (m).\n",
    "        xsat : Uydunun pozisyonu, ECEF koordinat sisteminde (m).\n",
    "        W : A\u011f\u0131rl\u0131k matrisi\n",
    "    Returns:\n",
    "        residuals*W : pseudorange rate art\u0131klar\u0131 , hatalar\u0131\n",
    "    \"\"\"\n",
    "    u, rng = los_vector(x[:3], xsat)\n",
    "\n",
    "    # Pseudorange rate hesaplamas\u0131 yapaca\u011f\u0131z:\n",
    "      # \u0130lk olarak uydu h\u0131z\u0131ndan kullan\u0131c\u0131 h\u0131z\u0131n\u0131 \u00e7\u0131kararak do\u011frultu vekt\u00f6r\u00fc (u) ile \u00e7arp\u0131p toplam\u0131n\u0131 al\u0131yoruz\n",
    "      # Burda da yine ayn\u0131 \u015fekilde D\u00fcnya d\u00f6nmesinin etkisini 'Sagnac Etkisi'ni g\u00f6z \u00f6n\u00fcnde bulunduruyoruz\n",
    "    rate = np.sum((vsat - v[:3]) * u, axis=1) + OMGE / CLIGHT * (vsat[:, 1] * x[0] + xsat[:, 1] * v[0] - vsat[:, 0] * x[1] - xsat[:, 0] * v[1])\n",
    "\n",
    "    # Rate'i buldu\u011fumuza g\u00f6re art\u0131klar\u0131 (prr ile tahmin edilen h\u0131z aras\u0131ndaki fark) hesaplayabiliriz\n",
    "    residuals = rate - (prr - v[3])\n",
    "\n",
    "    return residuals @ W"
   ],
   "metadata": {
    "id": "00ovy3-SOEq7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 7-  Arac\u0131n T\u00fcmsekten Ge\u00e7erken Z\u0131plmas\u0131 Dolay\u0131s\u0131yla Olu\u015fturdu\u011fu Ayk\u0131r\u0131 De\u011fer  ve \u0130nterpolasyonu (Veri D\u00fczeltme)\n",
    "\n",
    "Bu fonksiyon, ayk\u0131r\u0131 de\u011fer tespiti yaparak, \u00f6zellikle z ekseni \u00fczerindeki (yukar\u0131) h\u0131z bile\u015feninde belirledi\u011fimiz e\u015fik de\u011ferini a\u015fan anormal h\u0131zlar\u0131 (\u00f6rne\u011fin, ger\u00e7ekte bir ara\u00e7 yolda yatay olarak hareket ederken, GNSS verisi arac\u0131n aniden yukar\u0131 do\u011fru (havaya) f\u0131rlad\u0131\u011f\u0131 gibi bir h\u0131z de\u011feri rapor edebilir.) belirler ve bu de\u011ferleri ge\u00e7ici olarak ge\u00e7ersiz (NaN) olarak i\u015faretler. Daha sonra, eksik verileri interpolasyon y\u00f6ntemleriyle doldurarak hem pozisyon hem de h\u0131z verilerindeki hatalar\u0131 d\u00fczeltmemizi sa\u011flar. Bu fonksiyon sayesinde GNSS verilerinin daha do\u011fru ve tutarl\u0131 olmas\u0131n\u0131 ama\u00e7l\u0131yoruz:\n",
    "\n",
    "- Ayk\u0131r\u0131 de\u011fer tespitinde: Z eksenindeki h\u0131z bile\u015feni i\u00e7in belirli bir e\u015fi\u011fi a\u015fan de\u011ferler NaN olarak i\u015faretleyece\u011fiz.\n",
    "- Interpolasyon: Eksik (NaN) de\u011ferleri lineer veya spline interpolasyon y\u00f6ntemleriyle dolduraca\u011f\u0131z.\n",
    "(Kom\u015fu veri noktalar\u0131na g\u00f6re bir doldurma i\u015flemi yap\u0131l\u0131r):\n",
    "![image.png](data:image/png;base64,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)\n",
    "\n",
    "- y1 ve y2 -> Eksik verinin iki kom\u015fu noktas\u0131\n",
    "- x1 ve x2 -> Bu noktalar\u0131n indeksleri (zaman veya pozisyon bilgisi).\n",
    "- x -> eksik verinin indeksi"
   ],
   "metadata": {
    "id": "P4weQepIFt6b"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Koordinat Sistemleri ve\tKullan\u0131m Alanlar\u0131:\n",
    "\n",
    "- **ECEF**\tUydular aras\u0131 mesafe, k\u00fcresel analizler, uydu y\u00f6r\u00fcngelerinin modellenmesi.\n",
    "- **Jeodezik**, arazi \u00f6l\u00e7\u00fcm\u00fc, kullan\u0131c\u0131 odakl\u0131 konum g\u00f6sterimi.\n",
    "- **ENU**,\tYerel d\u00fczlemde hareket analizi (\u00f6rne\u011fin, bir arac\u0131n kuzeye do\u011fru h\u0131z\u0131), yerel navigasyon"
   ],
   "metadata": {
    "id": "w5YNJ9RZNAHv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Simple outlier detection and interpolation\n",
    "def exclude_interpolate_outlier(x_wls, v_wls):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x_wls : Konum vekt\u00f6r\u00fc\n",
    "        v_wls : H\u0131z vekt\u00f6r\u00fc\n",
    "    \"\"\"\n",
    "\n",
    "    # z ekseninde h\u0131z i\u00e7in e\u015fik de\u011ferimizi tan\u0131mlayal\u0131m (m/s)\n",
    "    v_up_th = 2.0\n",
    "\n",
    "\n",
    "    # Konum ve h\u0131z bilgilerini ECEF'ten farkl\u0131 bir koordinat sistemine d\u00f6n\u00fc\u015ft\u00fcrece\u011fiz:\n",
    "      # Konumu, ECEF'ten Jeodezik koordinata \u00e7evirdik. Jeodezik kkoordinatlar, d\u00fcnya y\u00fczeyi \u00fczerindeki noktalar\u0131 daha kolay temsil etmemizi sa\u011flayacak\n",
    "      # H\u0131z\u0131, ECEF'ten ENU koordinat sistemine \u00e7evirdik. ENU(Earth North Up), arac\u0131n hareket y\u00f6n\u00fcn\u00fc belirlememizi ve analiz etmemizi kolayla\u015ft\u0131r\u0131r.\n",
    "    x_llh = np.array(pm.ecef2geodetic(x_wls[:, 0], x_wls[:, 1], x_wls[:, 2])).T\n",
    "    v_enu = np.array(pm.ecef2enuv(v_wls[:, 0], v_wls[:, 1], v_wls[:, 2], x_llh[0, 0], x_llh[0, 1])).T\n",
    "\n",
    "\n",
    "    # H\u0131z vekt\u00f6r\u00fc belirledi\u011fiiz e\u015fik de\u011ferin \u00fcst\u00fcndyse ayk\u0131r\u0131 de\u011fer atamas\u0131 yap\u0131p uerine NaN de\u011feri at\u0131yoruz\n",
    "    # Burada asl\u0131nda bahsetti\u011fimiz \u015fey arabalar\u0131n t\u00fcmseklerden ge\u00e7erkenki yukar\u0131 do\u011fru olan h\u0131z vekt\u00f6r\u00fc\n",
    "    idx_v_out = np.abs(v_enu[:, 2]) > v_up_th\n",
    "    v_wls[idx_v_out, :] = np.nan\n",
    "\n",
    "\n",
    "    # Konum verilerindeki eksik de\u011ferleri interpolasyon y\u00f6ntemi ile dolduraca\u011f\u0131z\n",
    "    x_df = pd.DataFrame({'x': x_wls[:, 0], 'y': x_wls[:, 1], 'z': x_wls[:, 2]}) # konum verilerini df'e d\u00f6n\u00fc\u015ft\u00fcrd\u00fck\n",
    "    x_df = x_df.interpolate(limit_area='outside', limit_direction='both') # interpolasyon ile eksik verileri doldurduk (kom\u015fu veri noktalar\u0131na g\u00f6re)\n",
    "\n",
    "\n",
    "    # Ayn\u0131 \u015fekilde H\u0131z verilerindeki eksik de\u011ferleri interpolasyon y\u00f6ntemi ile dolduraca\u011f\u0131z\n",
    "    v_df = pd.DataFrame({'x': v_wls[:, 0], 'y': v_wls[:, 1], 'z': v_wls[:, 2]})\n",
    "    v_df = v_df.interpolate(limit_area='outside', limit_direction='both')\n",
    "    v_df = v_df.interpolate('spline', order=3) # k\u00fcbik spline y\u00f6ntemi kulland\u0131k. Bu sayede daha ak\u0131c\u0131 bir tahmin elde edebilece\u011fiz\n",
    "\n",
    "\n",
    "    return x_df.to_numpy(), v_df.to_numpy()"
   ],
   "metadata": {
    "id": "8x2JbdP1OIxC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 8- Kalman Filtreleme ve P\u00fcr\u00fczs\u00fczle\u015ftirme\n",
    "\n",
    "Kalman filtresi, dinamik sistemlerde en uygun durum tahminini sa\u011flayan ve zaman serisi verilerinin analizi i\u00e7in kullan\u0131lan bir algoritmad\u0131r. Bu filtre, \u00f6nceki durum bilgilerine dayanarak tahmin yapar ve yeni \u00f6l\u00e7\u00fcmleri entegre ederek sistemin mevcut durumunu optimize eder.\n",
    "\n",
    "\u0130lk olarak, ba\u015flang\u0131\u00e7 durumu belirlenir ve tahmin yap\u0131l\u0131r. Ard\u0131ndan, bir \u00f6l\u00e7\u00fcm elde edilir ve model ile \u00f6l\u00e7\u00fcm entegrasyonu Kalman kazanc\u0131 ile yap\u0131l\u0131r; kazan\u00e7, model ve \u00f6l\u00e7\u00fcm belirsizliklerine g\u00f6re ayarlan\u0131r. Bu tekrar eden tahmin-g\u00fcncelleme s\u00fcreci, daha do\u011fru tahminler yap\u0131lmas\u0131n\u0131 sa\u011flar\n",
    "\n",
    "GNSS konum iyile\u015ftirme sistemlerinde, \u00f6l\u00e7\u00fcm g\u00fcr\u00fclt\u00fclerini ve hatalar\u0131 azaltmak i\u00e7in yayg\u0131n olarak kullan\u0131lmaktad\u0131r. GNSS verilerinin Kalman filtresiyle i\u015flenmesinde durum ve g\u00f6zlem bilgilerini entegrasyon yoluyla daha hassas bir konum tahmini yap\u0131labilir. Kalman filtresi, sistemdeki g\u00fcr\u00fclt\u00fc ve belirsizlikleri en aza indirgeyerek en olas\u0131 durumu belirlemeyi ama\u00e7lar.\n",
    "\n",
    "Kalman Filtresi i\u00e7in basit\u00e7e \"ge\u00e7mi\u015ften ders alarak gelece\u011fi tahmin eder\" diyebiliriz."
   ],
   "metadata": {
    "id": "r96ifLvmFvJj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> Kalman Filtresi de \u00f6nceki verileri kullanarak tahmin yap\u0131yor, LSTM de. O zaman bu projede neden LSTM\u2019i de kulland\u0131n?\n",
    "\n",
    "\n",
    "\n",
    "Kalman Filtresi, sistemin davran\u0131\u015f\u0131n\u0131 \u00f6nceden tan\u0131mlanm\u0131\u015f fiziksel ve matematiksel modellere g\u00f6re tahmin eder. \u00d6rne\u011fin, GNSS sinyallerinde konum, h\u0131z ve ivme gibi parametrelerin zaman i\u00e7inde nas\u0131l de\u011fi\u015fti\u011fi, belirli hareket denklemleriyle ifade edilir ve bu modele uygun olarak tahmin yap\u0131l\u0131r. Ancak bu model belirli kabuller i\u00e7erir (\u00f6rne\u011fin: Gaussian g\u00fcr\u00fclt\u00fc, lineer hareket gibi) ve karma\u015f\u0131k, do\u011frusal olmayan sistemlerde ya da veri kalitesi d\u00fc\u015f\u00fck oldu\u011funda s\u0131n\u0131rl\u0131 performans g\u00f6sterir.\n",
    "\n",
    "LSTM ise, ge\u00e7mi\u015f verilerden temsil\u00ee kal\u0131plar\u0131 \u00f6\u011frenerek bu s\u0131n\u0131rlamalar\u0131 a\u015fabilir. \u00d6zellikle GNSS sinyalleri gibi zaman serisi i\u00e7inde trend, \u00f6r\u00fcnt\u00fc ve bozulmalar\u0131n modellenmesi gerekti\u011fi durumlarda, LSTM ge\u00e7mi\u015f verilerin ba\u011flam\u0131n\u0131 daha uzun vadede tutabilir. Bu sayede:\n",
    "\n",
    "  - Non-lineer ili\u015fkileri \u00f6\u011frenebilir,\n",
    "\n",
    "  - Atmosferik ve \u00e7evresel ko\u015fullardan do\u011fan belirsizlikleri modelleyebilir,\n",
    "\n",
    "  - \u00d6nceden tan\u0131mlanmam\u0131\u015f anomalilere kar\u015f\u0131 esnek olabilir.\n",
    "\n",
    "Projemde Kalman filtresi ile \u00f6n i\u015flem yap\u0131lm\u0131\u015f veriler, ard\u0131ndan LSTM'e beslenmi\u015ftir. B\u00f6ylece:\n",
    "\n",
    "  - Kalman filtresiyle g\u00fcr\u00fclt\u00fc azalt\u0131lm\u0131\u015f ve veriler yumu\u015fat\u0131lm\u0131\u015f,\n",
    "\n",
    "  - LSTM modeli de ge\u00e7mi\u015f \u00f6r\u00fcnt\u00fclerden \u00f6\u011frenerek daha g\u00fc\u00e7l\u00fc konum tahminleri yapm\u0131\u015ft\u0131r.\n",
    "\n",
    "  - Bu hibrit yakla\u015f\u0131m, yaln\u0131zca fiziksel modellemeye ya da yaln\u0131zca veri \u00f6\u011frenimine dayal\u0131 y\u00f6ntemlerden daha \u00fcst\u00fcn performans sa\u011flam\u0131\u015ft\u0131r.\n",
    "\n",
    "K\u0131saca: Kalman daha iyi filtreler, LSTM daha iyi tahmin eder. Bu projede ikisini birle\u015ftirmek, her iki y\u00f6ntemin g\u00fc\u00e7l\u00fc yanlar\u0131n\u0131 bir araya getirmi\u015ftir."
   ],
   "metadata": {
    "id": "jfQs73vMVHUQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`Mahalanobis mesafesi`, \u00f6zellikle \u00e7ok de\u011fi\u015fkenli verilerde ayk\u0131r\u0131 de\u011ferleri tespit etmek ve \u00f6l\u00e7\u00fcmler aras\u0131 ili\u015fkileri dikkate almak i\u00e7in kullan\u0131lan g\u00fc\u00e7l\u00fc bir istatistiksel \u00f6l\u00e7\u00fctt\u00fcr. Kalman filtresi gibi durum tahmini algoritmalar\u0131nda, \u00f6l\u00e7\u00fcm\u00fcn modele ne kadar uyumlu oldu\u011funu belirlemek i\u00e7in s\u0131kl\u0131kla kullan\u0131l\u0131r.\n",
    "\n",
    "Mahalanobis mesafesi asl\u0131nda \u00e7ok de\u011fi\u015fkenli bir \"z-skoru\" gibidir. \u00d6rne\u011fin:\n",
    "\n",
    " - Mahalanobis mesafesi = 1 \u2192 Ortalama de\u011ferin bir standart sapma uza\u011f\u0131nda\n",
    "\n",
    " - Mahalanobis mesafesi = 3 \u2192 Ortalama de\u011ferin \u00fc\u00e7 standart sapma uza\u011f\u0131nda\n",
    "\n",
    " - Mahalanobis mesafesi = 30 \u2192 Ayk\u0131r\u0131 u\u00e7ta, \u00e7ok uzak bir \u00f6l\u00e7\u00fcm\n",
    "\n",
    "Kalman filtresi bir tahmin y\u00fcr\u00fct\u00fcr ve d\u0131\u015far\u0131dan gelen g\u00f6zlemlerle bu tahmini d\u00fczeltir. Ancak g\u00f6zlemler bazen hatal\u0131 olabilir. \u0130\u015fte Mahalanobis mesafesi, \u201cBu g\u00f6zlem bekledi\u011fimden \u00e7ok mu farkl\u0131?\u201d diye soran bir dedekt\u00f6rd\u00fcr. E\u011fer cevap \u201cEvet, \u00e7ok farkl\u0131\u201d ise g\u00f6zlemi dikkate almaz.\n",
    "\n",
    "Bu Projedeki Rol\u00fc (Kalman Filtresinde)\n",
    " - Kalman filtresi her \u00f6l\u00e7\u00fcmde bir tahmin yapar ve bu tahmine gelen ger\u00e7ek \u00f6l\u00e7\u00fcm\u00fc kar\u015f\u0131la\u015ft\u0131rarak g\u00fcncelleme yapar.\n",
    "\n",
    " - E\u011fer gelen \u00f6l\u00e7\u00fcm, tahmin edilen de\u011ferden \u00e7ok fazla sapm\u0131\u015fsa (yani Mahalanobis mesafesi b\u00fcy\u00fckse), bu \u00f6l\u00e7\u00fcm \"ayk\u0131r\u0131\" kabul edilir.\n",
    "\n",
    " - Belirlenen e\u015fik (\u00f6rne\u011fin sigma_mahalanobis = 30.0) bir g\u00fcven seviyesi belirler. Bu de\u011ferin \u00fcst\u00fcnde kalan \u00f6l\u00e7\u00fcmler filtreye dahil edilmez.\n",
    "\n",
    " - Mahalanobis mesafesi sayesinde Kalman filtresi bu anormal de\u011ferleri ay\u0131klayabilir, bu da daha sa\u011flam ve kararl\u0131 tahminler sa\u011flar.\n",
    "\n",
    " - Bu sayede Kalman filtresi, yanl\u0131\u015f/bozulmu\u015f GNSS \u00f6l\u00e7\u00fcmlerinden etkilenmeden \u00e7al\u0131\u015fabilir.\n",
    "\n"
   ],
   "metadata": {
    "id": "pZFF28dCZLg1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Kalman filter\n",
    "def Kalman_filter(zs, us, phone):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        zs : konum \u00f6l\u00e7\u00fcmleri (her g\u00f6zlem 3 bile\u015fenden olu\u015facak -> x y z)\n",
    "        us : h\u0131z bilgisi  (her g\u00f6zlem 3 bile\u015fenden olu\u015facak -> x y z)\n",
    "        phone : kullan\u0131lan telefon modeli\n",
    "    \"\"\"\n",
    "    # TANIMLAMALAR:\n",
    "\n",
    "    # H\u0131z\u0131n Standart Sapmas\u0131\n",
    "    sigma_v = 0.6 if phone == 'XiaomiMi8' else 0.1 # Xiomi marka telefonlarda daha y\u00fcksek bir hata pay\u0131 b\u0131rak\u0131yoruz. \u00c7\u00fcnk\u00fc bu telefonlarda dah b\u00fcy\u00fck hata pay\u0131 oldu\u011fu varsay\u0131l\u0131yor\n",
    "    # Konumun Standart Sapmas\u0131\n",
    "    sigma_x = 5.0  # (metre)\n",
    "    # Mahalanobis mesafesini belirliyoruz. (asl\u0131nda kalman filtremizdeki e\u015fik de\u011ferimiz gibi d\u00fc\u015f\u00fcnebiliriz)\n",
    "      # Mahalanobis mesafesi, g\u00f6zlemlenen de\u011ferlerin mevcut modelden ne kadar farkl\u0131 oldu\u011funu \u00f6l\u00e7en bir istatistiksel \u00f6l\u00e7\u00fct.\n",
    "      # Kalman fitrlemenin geri beslemesinde e\u011fer g\u00f6zlem bu de\u011ferden b\u00fcy\u00fckse ayk\u0131r\u0131 g\u00f6zlem olarak kabul edilecek ve filtreleme s\u00fcrecine dahil edilmeyecek\n",
    "      # Yani amac\u0131, ayk\u0131r\u0131 g\u00f6zlemleri filtrelemek bir nevi\n",
    "    sigma_mahalanobis = 30.0\n",
    "\n",
    "    n, dim_x = zs.shape # Konum \u00f6l\u00e7\u00fcmlerinin say\u0131s\u0131 = n , durum vekt\u00f6r\u00fcn\u00fcn boyutu = dim_x (her \u00f6l\u00e7\u00fcm i\u00e7in 3 boyutlu olacak dolay\u0131s\u0131yla dim_x = 3 olacak)\n",
    "    F = np.eye(3)  # Ge\u00e7i\u015f matrisimiz (sisteminin durum ge\u00e7i\u015flerini tan\u0131mlayacak). 3x3'l\u00fck birim matrisi olu\u015fturduk.\n",
    "    Q = sigma_v**2 * np.eye(3)  # \u0130\u015flem g\u00fcr\u00fclt\u00fcs\u00fc matrisimiz. H\u0131z\u0131n standart sapmas\u0131n\u0131n karesini F (ge\u00e7i\u015f matirisi) ile \u00e7arp\u0131yoruz.\n",
    "                                # S\u0130stemde beklenen g\u00fcr\u00fclt\u00fc miktar\u0131n\u0131 temsil edecek. Zamanla biriken hatalar\u0131 modellemede kullanaca\u011f\u0131z\n",
    "\n",
    "    H = np.eye(3)  # Sistemin ger\u00e7ek durumunu \u00f6l\u00e7\u00fcmlerle ili\u015fkilendirmek i\u00e7in 3x3'l\u00fck birim matrisimiz (\u00d6l\u00e7\u00fcm Matrisi)\n",
    "    R = sigma_x**2 * np.eye(3)  # \u00d6l\u00e7\u00fcm g\u00fcr\u00fclt\u00fcs\u00fc matrisimiz. Konumun standart sapmas\u0131n\u0131n karesini birim matris ile \u00e7arp\u0131yoruz.\n",
    "                                # \u00d6l\u00e7\u00fcmlerin ne kadar g\u00fcr\u00fclt\u00fcl\u00fc oldu\u011funu veya ne kadar g\u00fcvenilir oldu\u011funu belirtecek. R ne kadar k\u00fc\u00e7\u00fckse o kadar g\u00fcvenilirdir.\n",
    "\n",
    "    # Ba\u015flang\u0131\u00e7 \u200b\u200bdurumu ve kovaryans\n",
    "    x = zs[0, :3].T  # ba\u015flang\u0131\u00e7 durumumuz (konum vekt\u00f6r\u00fcn\u00fcn transpozu)\n",
    "    P = sigma_x**2 * np.eye(3)  # ba\u015flang\u0131\u00e7taki kovaryans yani belirsizlik\n",
    "    I = np.eye(dim_x) # birim matrisimiz\n",
    "\n",
    "    x_kf = np.zeros([n, dim_x]) # her ad\u0131m\u0131nda elde edilen durum vekt\u00f6rlerinin s\u0131ras\u0131yla saklayaca\u011f\u0131m\u0131z dizi (ba\u015flang\u0131\u00e7 de\u011feri = 0)\n",
    "    P_kf = np.zeros([n, dim_x, dim_x])  # her ad\u0131m\u0131nda elde edilen kovaryans matrislerini s\u0131ras\u0131yla saklayaca\u011f\u0131m\u0131z dizi (ba\u015flang\u0131\u00e7 de\u011feri = 0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # KALMAN F\u0130LTRELEME yapabiliriz art\u0131k:\n",
    "    for i, (u, z) in enumerate(zip(us, zs)):\n",
    "        # \u0130lk ad\u0131m\u0131m\u0131z\n",
    "        if i == 0:\n",
    "            x_kf[i] = x.T # ilk durumu kaydettik\n",
    "            P_kf[i] = P # ilk kovaryans\u0131 kaydettik -> sistemin g\u00fcvenilirli\u011fini \u00f6l\u00e7ecek\n",
    "            continue\n",
    "\n",
    "        # Tahmin ad\u0131m\u0131\n",
    "        x = F @ x + u.T # durumla ilgili yeni tahminimiz F@x + h\u0131z\u0131n transpozesi\n",
    "        P = (F @ P) @ F.T + Q # bu tahminin kovaryans\u0131. Ne kadar g\u00fcvenilir oldu\u011fu\n",
    "\n",
    "        # Mahalonabis mesafesini kullanarak ayk\u0131r\u0131 de\u011ferleri kontrol ediyoruz. E\u015fik de\u011ferimizi yukar\u0131da tan\u0131mlam\u0131\u015ft\u0131k\n",
    "        d = distance.mahalanobis(z, H @ x, np.linalg.pinv(P)) # z g\u00f6zlemimiz , H@x tahminimiz , np.linalg.pinv(P) kovaryans matrisimiz(g\u00fcvenilirli\u011fi \u00f6l\u00e7ecek)\n",
    "\n",
    "        # G\u00fcncelleme ad\u0131m\u0131.\n",
    "        if d < sigma_mahalanobis: # E\u011fer mesafemiz en ba\u015fta belirledi\u011fimiz mahalonabis de\u011ferinden d\u00fc\u015f\u00fckse yani g\u00f6zlem ayk\u0131r\u0131 DE\u011e\u0130LSE\n",
    "            y = z.T - H @ x # g\u00f6zlemimizle tahminimiz aras\u0131ndaki fark\n",
    "            S = (H @ P) @ H.T + R # sistemin g\u00fcvenilirli\u011fini \u00f6l\u00e7en kovaryans matrisi\n",
    "            K = (P @ H.T) @ np.linalg.inv(S)  # kalman kazanc\u0131m\u0131z. g\u00f6zlemlerle tahminler aras\u0131ndaki fark\u0131 ne kadar dikkate alaca\u011f\u0131m\u0131z\u0131 belirleyen bir katsay\u0131\n",
    "            x = x + K @ y # g\u00fcncellenmi\u015f durum vekt\u00f6r\u00fc\n",
    "            P = (I - (K @ H)) @ P # ba\u015flang\u0131\u00e7taki kovaryans matrisini g\u00fcncelliyoruz\n",
    "        else: # ayk\u0131r\u0131 ise\n",
    "            P += 10**2*Q   # kovaryans matrisini art\u0131rarak g\u00f6zlemlerle ili\u015fkisini azaltaca\u011f\u0131z. Yani daha az g\u00fcvenilirdir diyece\u011fiz\n",
    "\n",
    "        x_kf[i] = x.T # durum vekt\u00f6rlerimiz\n",
    "        P_kf[i] = P   # kovaryans vekt\u00f6rlerimiz\n",
    "\n",
    "    return x_kf, P_kf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# KALMAN P\u00dcR\u00dcZS\u00dcZLE\u015eT\u0130RME\n",
    "# \u0130leri + geri Kalman filtresi ve p\u00fcr\u00fczs\u00fczle\u015ftirme\n",
    "  # Bu sayede verileri daha da hassasla\u015ft\u0131rarak konum ve h\u0131z verilerinin do\u011frulu\u011funu art\u0131raca\u011f\u0131z\n",
    "\n",
    "def Kalman_smoothing(x_wls, v_wls, phone):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        x_wls : Konum vekt\u00f6r\u00fc\n",
    "        v_wls : H\u0131z vekt\u00f6r\u00fc\n",
    "        phone : Kullan\u0131lan telefon modeli\n",
    "    \"\"\"\n",
    "\n",
    "    n, dim_x = x_wls.shape # ayn\u0131 \u00fcstteki gibi konum vekt\u00f6rlerinin say\u0131s\u0131 = n , durum vekt\u00f6r\u00fcn\u00fcn boyutu = dim_x (her \u00f6l\u00e7\u00fcm i\u00e7in 3 boyutlu olacak dolay\u0131s\u0131yla dim_x = 3 olacak)\n",
    "\n",
    "    # \u0130leri filtreleme\n",
    "    v = np.vstack([np.zeros([1, 3]), (v_wls[:-1, :] + v_wls[1:, :])/2]) # h\u0131z verilerinin ortak noktas\u0131n\u0131 bulur (iki ardal\u0131k veri aras\u0131nda)\n",
    "    x_f, P_f = Kalman_filter(x_wls, v, phone) # Kalman filtresini \u00e7a\u011f\u0131rarak konum ve kovaryans tahmini yap\u0131yoruz\n",
    "\n",
    "    # Geri filtreleme\n",
    "    v = -np.flipud(v_wls) # geri filtreleme yapaca\u011f\u0131m\u0131z i\u00e7in h\u0131z verilerinin s\u0131ras\u0131n\u0131 tersine \u00e7evirdik\n",
    "    v = np.vstack([np.zeros([1, 3]), (v[:-1, :] + v[1:, :])/2])\n",
    "    x_b, P_b = Kalman_filter(np.flipud(x_wls), v, phone)  # Yine Kalman filtresini \u00e7a\u011f\u0131rd\u0131k. Bu sefer ge\u00e7mi\u015fteki verileri g\u00f6z \u00f6n\u00fcne alarak daha do\u011fru bir tahmin yapaca\u011f\u0131z\n",
    "\n",
    "    # P\u00fcr\u00fczs\u00fczle\u015ftirme\n",
    "    x_fb = np.zeros_like(x_f) # Hem ileri hem de geri y\u00f6nde d\u00fczeltilmi\u015f konum tahminleri\n",
    "    P_fb = np.zeros_like(P_f) # Hem ileri hem de geri y\u00f6nde d\u00fczeltilmi\u015f h\u0131z tahminleri\n",
    "    for (f, b) in zip(range(n), range(n-1, -1, -1)):\n",
    "        P_fi = np.linalg.inv(P_f[f])  # ileri kovaryans matrisinin tersi\n",
    "        P_bi = np.linalg.inv(P_b[b])  # Geri kovaryans matrisinin tersi\n",
    "\n",
    "        P_fb[f] = np.linalg.inv(P_fi + P_bi)  # ileri ve geri kovaryan matrislerinin toplam\u0131n\u0131n tersi. Bu sayede ileri ve geriyi birle\u015ftirdik\n",
    "        x_fb[f] = P_fb[f] @ (P_fi @ x_f[f] + P_bi @ x_b[b]) # ileri ve geri tahminleri birle\u015ftirdik ve p\u00fcr\u00fczs\u00fczle\u015ftirmeyi yapm\u0131\u015f olduk\n",
    "\n",
    "    return x_fb, x_f, np.flipud(x_b)  # ileri-geri konum tahmini , ileri konum tahmini ve geri konum tahminini geri d\u00f6nd\u00fcrd\u00fck"
   ],
   "metadata": {
    "id": "epEVIGCFOXjN"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 9- Veri Setimize Bu \u00d6n \u0130\u015fleme Tekniklerinin Uygulanmas\u0131"
   ],
   "metadata": {
    "id": "VUyioT4tFwCo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# Ana veri seti klas\u00f6r\u00fcm\n",
    "root_path = \"/content/drive/MyDrive/BitirmeProjesi/smartphone-decimeter-2022/train\"\n",
    "\n",
    "# S\u00fcr\u00fc\u015f oturumlar\u0131n\u0131 listelelemek i\u00e7in bir for d\u00f6ng\u00fcs\u00fc yazaca\u011f\u0131z\n",
    "drive_sessions = [d for d in os.listdir(root_path) if os.path.isdir(os.path.join(root_path, d))]\n",
    "print(\"T\u00fcm s\u00fcr\u00fc\u015f oturumlar\u0131:\", drive_sessions)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0jwRKRiskEnr",
    "outputId": "7c1357f4-ef29-4ee2-e36c-9e2c8a3ad409"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# \u00d6rnek olarak bir s\u00fcr\u00fc\u015f oturumunu se\u00e7elim\n",
    "selected_drive = \"2021-07-19-US-MTV-1\"  # Bunu dinamik hale getirebiliriz\n",
    "\n",
    "# Ve bu se\u00e7ilen s\u00fcr\u00fc\u015f oturumundaki telefonlar\u0131 listeleyelim\n",
    "drive_path = os.path.join(root_path, selected_drive)\n",
    "phones = [p for p in os.listdir(drive_path) if os.path.isdir(os.path.join(drive_path, p))]\n",
    "\n",
    "print(f\"{selected_drive} oturumundaki telefonlar:\", phones)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3kOD-t0rkF20",
    "outputId": "7717d805-49ed-41a3-b957-832379700444"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Oturum A\u00e7\u0131klamalar\u0131:\n",
    "\n",
    "- MTV (Mountain View, CA) \u2192 Google\u2019\u0131n ana merkezinin bulundu\u011fu b\u00f6lge, Silikon Vadisi\u2019nde yer al\u0131r.\n",
    "- SJC (San Jose, CA) \u2192 San Jose kodu, yine Silikon Vadisi b\u00f6lgesinde yer al\u0131r.\n",
    "- SFO (San Francisco, CA) \u2192 San Francisco.\n",
    "- SVL (Silicon Valley, CA) \u2192 Silikon Vadisi genelini kapsayan bir kod.\n",
    "- LAX (Los Angeles, CA) \u2192 Los Angeles kodu."
   ],
   "metadata": {
    "id": "nAkuFGUjYx-O"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# \u00dcstteki 2 kodu birle\u015ftirerek daha a\u00e7\u0131klay\u0131c\u0131 bir liste olu\u015ftural\u0131m:\n",
    "\n",
    "# T\u00fcm s\u00fcr\u00fc\u015f oturumlar\u0131n\u0131 alal\u0131m\n",
    "drive_sessions = [d for d in os.listdir(root_path) if os.path.isdir(os.path.join(root_path, d))]\n",
    "\n",
    "# Her oturum i\u00e7in telefonlar\u0131 getirelim\n",
    "all_data = {}\n",
    "\n",
    "for drive in drive_sessions:\n",
    "    drive_path = os.path.join(root_path, drive)\n",
    "    phones = [p for p in os.listdir(drive_path) if os.path.isdir(os.path.join(drive_path, p))]\n",
    "    all_data[drive] = phones\n",
    "\n",
    "# Sonu\u00e7lar\u0131 yazd\u0131ral\u0131m\n",
    "for drive, phones in all_data.items():\n",
    "    print(f\"{drive} oturumundaki telefonlar: {phones}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tDeZd5rukH-7",
    "outputId": "2b1c37ef-0091-4451-98c5-ce6b40c62e8b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Kullan\u0131c\u0131n\u0131n istedi\u011fi veri setini se\u00e7mesini isteyelim\n",
    "selected_drive = input(\"Hangi s\u00fcr\u00fc\u015f oturumunu kullanmak istiyorsunuz? \")\n",
    "selected_phone = input(\"Hangi telefonu kullanmak istiyorsunuz? \")\n",
    "\n",
    "# Veri Setimizin bulundu\u011fu path'i olu\u015fturuyoruz\n",
    "path = os.path.join(root_path, selected_drive, selected_phone)\n",
    "\n",
    "print(f\"Se\u00e7ilen veri yolu: {path}\")\n",
    "\n",
    "# Drive'\u0131m\u0131zda depolad\u0131\u011f\u0131m\u0131z GNSS \u00f6l\u00e7\u00fcm veri seti ile ger\u00e7ek konum verilerini ie\u00e7eren dataframe'lerimiz\n",
    "gnss_df = pd.read_csv(f'{path}/device_gnss.csv')  # GNSS verileri\n",
    "gt_df = pd.read_csv(f'{path}/ground_truth.csv')  # Ger\u00e7ek veriler\n",
    "\n",
    "\n",
    "\n",
    "# GNSS verilerimize yazd\u0131\u011f\u0131m\u0131z 'point_positioning' fonksiyonumuzu uygulayarak kullan\u0131c\u0131n\u0131n konum ve h\u0131z tespitini yap\u0131yoruz\n",
    "utc, x_wls, v_wls = point_positioning(gnss_df)\n",
    "\n",
    "# Konum ve h\u0131z vekt\u00f6rlerindeki ayk\u0131r\u0131 ya da NaN de\u011ferleri yazd\u0131\u011f\u0131m\u0131z \"exclude_interpolate_outlier\" fonksiyonu ile interpolasyonla tespit ediyoruz ve dolduruyoruz\n",
    "x_wls, v_wls = exclude_interpolate_outlier(x_wls, v_wls)\n",
    "\n",
    "# Yazd\u0131\u011f\u0131m\u0131z \"Kalman_smoothing\" fonksiyonu ile h\u0131z ve konum tahminimizin do\u011frulu\u011funu art\u0131r\u0131yoruz\n",
    "x_kf, _, _ = Kalman_smoothing(x_wls, v_wls, selected_phone)\n",
    "\n",
    "# Veri setini ECEF koorinat sisteminden Jeodezik Koor. Sis. \u00e7evirerek enlem, boylam ve y\u00fckseklik sistemine d\u00f6n\u00fc\u015ft\u00fcr\u00fcyoruz\n",
    "# 10. b\u00f6l\u00fcmde bunlar\u0131 kullanaca\u011f\u0131z\n",
    "llh_wls = np.array(pm.ecef2geodetic(x_wls[:, 0], x_wls[:, 1], x_wls[:, 2])).T # \"point_positioning\"den elde edilen h\u0131z ve konum koordinatlar\u0131\n",
    "llh_kf = np.array(pm.ecef2geodetic(x_kf[:, 0], x_kf[:, 1], x_kf[:, 2])).T # kalman filtresi sonucu iyile\u015ftirilen h\u0131z ve konum koordinatlar\u0131\n",
    "\n",
    "# Ger\u00e7ek verilerle (gt_df) kar\u015f\u0131la\u015ft\u0131rmak i\u00e7in fonksiyonlar sonucu ortaya \u00e7\u0131kacak \"gnss_df\"imizi haz\u0131rlayarak referans noktas\u0131 (base line) olu\u015fturuyoruz\n",
    "x_bl = gnss_df.groupby('TimeNanos')[['WlsPositionXEcefMeters', 'WlsPositionYEcefMeters', 'WlsPositionZEcefMeters']].mean().to_numpy() # GNSS verilerinde her zaman dilimi i\u00e7in pozisyon tahminlerinin ortalamas\u0131\n",
    "llh_bl = np.array(pm.ecef2geodetic(x_bl[:, 0], x_bl[:, 1], x_bl[:, 2])).T # \u00fcstteki tahmini enlem, boylam ve y\u00fckseklik format\u0131na d\u00f6n\u00fc\u015ft\u00fcrd\u00fck"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104,
     "referenced_widgets": [
      "b0befd21d59f4c1b9dcc9f55990de35b",
      "01bf83384dfd4da9bf149210022b3748",
      "d1e61c7a3ed643d7802d63a638f00aa1",
      "041a03ffa0ad41179d7194c789f60756",
      "90242ad2464e47ad9f6756346189aeea",
      "e68e8a2e3400432dbddf3c03859c703b",
      "261362d6a63a4171a31d92fcf5dfe177",
      "102ad51281e547b8b26d881a05e26248",
      "b661c9538dd7464b8162a13c75f232c8",
      "0930cfeb273d47219d652350fa970576",
      "bdce174c316e45e0b6829a3909866a3c"
     ]
    },
    "id": "AOUu1Ng_ObnM",
    "outputId": "a7a74388-db87-432f-ceaf-f0157174b5f0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 10- Kar\u015f\u0131la\u015ft\u0131rmak \u0130\u00e7in Skor Hesaplanmas\u0131 ve Skorlar\u0131n Yorumlanmas\u0131\n",
    "\n",
    "Vincenty Form\u00fcl\u00fc, bir k\u00fcrenin y\u00fczeyindeki iki nokta aras\u0131ndaki mesafeyi hesaplamak i\u00e7in kullan\u0131lan y\u00f6ntemdir.\n",
    "<br></br>\n",
    "\n",
    "<h3 style=\"color:blue;\">Skorlar\u0131n Yorumlanmas\u0131</h3>\n",
    "\n",
    "1. **Referans Noktas\u0131 Skoru (2.1929 metre):**\n",
    "\n",
    "- Bu skor, temel modelin performans\u0131n\u0131 g\u00f6sterir.\n",
    "- D\u00fc\u015f\u00fck do\u011fruluk bekledi\u011fimiz bir referans olarak d\u00fc\u015f\u00fcnebiliriz.\n",
    "<br></br>\n",
    "\n",
    "2. **WLS Skoru (1.9769 metre):**\n",
    "\n",
    "- Weighted Least Squares (WLS), GNSS verilerindeki hatalar\u0131 azaltmak i\u00e7in kulland\u0131\u011f\u0131m\u0131z bir y\u00f6ntemdi zaten.\n",
    "- Baseline skorundan daha d\u00fc\u015f\u00fck bir de\u011fer, bu y\u00f6ntemin ile birlikte pozisyon do\u011frulu\u011funu art\u0131rd\u0131\u011f\u0131m\u0131z\u0131 g\u00f6sterir.\n",
    "- Bu y\u00f6ntemle elde etti\u011fimiz skorumuz Baseline'a g\u00f6re yakla\u015f\u0131k %9.85 iyile\u015fme g\u00f6steriyor.\n",
    "<br></br>\n",
    "\n",
    "3. **Kalman Filtresi Skoru (1.1443 metre):**\n",
    "\n",
    "- Kalman filtresi, zaman serisi verilerindeki hatalar\u0131 daha ileri d\u00fczeyde filtrelemesi ve pozisyon tahminlerini daha da iyile\u015ftirmesi i\u00e7in kullanm\u0131\u015ft\u0131k.\n",
    "- Bu skor genellikle en d\u00fc\u015f\u00fck olmal\u0131d\u0131r.\n",
    "- E\u011fer ger\u00e7ek d\u00fcnya uygulamalar\u0131nda y\u00fcksek hassasiyet elde etmemiz gerekiyorsa (\u00f6rne\u011fin, otonom ara\u00e7lar, navigasyon sistemleri), Kalman filtresiyle elde etti\u011fimiz sonu\u00e7lar daha kritiktir.\n",
    "- Kalman Filtresi ile elde etti\u011fimiz skor WLSE'e g\u00f6re %42.12 , Baseline'a g\u00f6re ise yakla\u015f\u0131k %47.82  daha iyi bir sonu\u00e7 sa\u011fl\u0131yor.\n",
    "<br></br>\n",
    "\n",
    "Genel olarak bakt\u0131\u011f\u0131m\u0131zda; sonu\u00e7lar, her ad\u0131mda modelin do\u011frulu\u011funun artt\u0131\u011f\u0131n\u0131 ve Kalman filtresi ile iyi bir do\u011fruluk seviyesine ula\u015ft\u0131\u011f\u0131m\u0131z\u0131 g\u00f6steriyor.\n"
   ],
   "metadata": {
    "id": "2jhVF_1CgX7a"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Bu fonksiyon vincenty y\u00f6ntemini kullanarak iki enlem ve boylam noktas\u0131n\u0131 aras\u0131ndaki mesafeyi hesaplayacak\n",
    "def vincenty_distance(llh1, llh2):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        llh1 : \u0130lk noktan\u0131n enlem ve boylam bilgisi (derece cinsinden)\n",
    "        llh2 : \u0130kinci noktan\u0131n enlem ve boylam bilgisi (derece cinsinden)\n",
    "    Returns:\n",
    "        d : \u0130ki nokta aras\u0131ndaki mesafe (m)\n",
    "    \"\"\"\n",
    "    d, az = np.array(pmv.vdist(llh1[:, 0], llh1[:, 1], llh2[:, 0], llh2[:, 1])) # PyMap k\u00fct\u00fcphanesindeki vincenty uzakl\u0131k form\u00fcl\u00fcn\u00fc kulland\u0131k mesaheyi hesaplamak i\u00e7in\n",
    "                                                                                # buradaki az -> azimut a\u00e7\u0131s\u0131 = bir noktan\u0131n di\u011fer bir noktaya olan y\u00f6n\u00fcn\u00fc belirten bir a\u00e7\u0131 ...\n",
    "                                                                                # ... iki nokta aras\u0131ndaki y\u00f6n\u00fc bulmak i\u00e7in kullanaca\u011f\u0131z. \u015eu an burada kullanmad\u0131k\n",
    "\n",
    "    return d\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Bu fonks ile GNSS \u00f6l\u00e7\u00fcmleriyle ger\u00e7ek \u00f6l\u00e7\u00fcmleri (ground_truth) kar\u0131\u015f\u0131l\u015ft\u0131rarak skoru hesaplayaca\u011f\u0131z\n",
    "def calc_score(llh, llh_gt):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        llh : Tahmin edilen enlem ve boylamlar (derece cinsinden)\n",
    "        llh_gt : Ger\u00e7ek enlem ve boylamlar (\"ground truth\")\n",
    "    Returns:\n",
    "        score : (m)\n",
    "    \"\"\"\n",
    "    d = vincenty_distance(llh, llh_gt)  # tahmin ve ger\u00e7ek konum aras\u0131ndaki uzakl\u0131\u011f\u0131 tuttuk\n",
    "    score = np.mean([np.quantile(d, 0.50), np.quantile(d, 0.95)]) # 0.5'lik \u00e7eyreklik -> tipik hatay\u0131 g\u00f6sterecek\n",
    "                                                                  # 0.95'lik \u00e7eyreklik -> y\u00fcksek hatalar\u0131 (GPS sinyali k\u00f6t\u00fc olan b\u00f6lgelerde ise) g\u00f6sterecek\n",
    "                                                                  # Bu ikisinin ortalamas\u0131n\u0131 alarak hem ortalama do\u011frulu\u011fu hem de k\u00f6t\u00fc senaryolar\u0131 ayn\u0131 anda g\u00f6z \u00f6n\u00fcnde bulunduraca\u011f\u0131z\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Ger\u00e7ek konum verilerimizi Enlem ve Boylam olarak alarak kar\u015f\u0131la\u015ft\u0131rmak i\u00e7in numpy'a d\u00f6n\u00fc\u015ft\u00fcr\u00fcyoruz\n",
    "llh_gt = gt_df[['LatitudeDegrees', 'LongitudeDegrees']].to_numpy()\n",
    "\n",
    "# GNSS verilerimizin skorlar\u0131n\u0131 ger\u00e7ek verilere olan uzakl\u0131\u011f\u0131n\u0131 bulaca\u011f\u0131z\n",
    "vd_bl = vincenty_distance(llh_bl, llh_gt) # referans noktam\u0131zla (\u00f6n i\u015flemeler sonucu) ger\u00e7ek tahminler aras\u0131 uzakl\u0131k\n",
    "vd_wls = vincenty_distance(llh_wls, llh_gt) # Dayan\u0131kl\u0131 A\u011f\u0131rl\u0131kl\u0131 En K\u00fc\u00e7\u00fck Kareler Y\u00f6nemi (point_positioning sonucu) ile ger\u00e7ek tahminler aras\u0131 uzakl\u0131k\n",
    "vd_kf = vincenty_distance(llh_kf, llh_gt) # Kalman Filtresi sonucu ile ger\u00e7ek tahminler aras\u0131 uzakl\u0131k\n",
    "\n",
    "# Bu 3 uzakl\u0131\u011f\u0131n da ayr\u0131 ayr\u0131 skorunu hesaplayaca\u011f\u0131z\n",
    "score_bl = calc_score(llh_bl, llh_gt) # Referans Noktas\u0131 (Baseline) skoru\n",
    "score_wls = calc_score(llh_wls, llh_gt) # WLS skoru\n",
    "score_kf = calc_score(llh_kf[:-1, :], llh_gt[:-1, :]) # Kalman filtresi skoru\n",
    "\n",
    "print(f'Referans Noktas\u0131 (Baseline) Skoru: {score_bl:.4f} [metre]')\n",
    "print(f'WLS Y\u00f6ntemi Skoru: {score_wls:.4f} [metre]')\n",
    "print(f'Kalman Filtresi skoru: {score_kf:.4f} [metre]')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WgX2FU-bgYQX",
    "outputId": "ac1ecfd9-3306-4c2d-b2ed-ba3aa6108570"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 11- Konum ve H\u0131z Hatalar\u0131n\u0131n G\u00f6rselle\u015ftirilmesi\n",
    "\n",
    "<h3>Grafiklerin Yorumlanmas\u0131</h3>\n",
    "\n",
    "- \u0130lk Grafik\n",
    "\n",
    "Bu grafikte \u00fcstte skorunu hesaplad\u0131\u011f\u0131m\u0131z \u00fc\u00e7 farkl\u0131 y\u00f6ntemin mesafe hatalar\u0131n\u0131 kar\u015f\u0131la\u015ft\u0131r\u0131l\u0131yoruz ve g\u00f6rselde her bir y\u00f6ntemin performans\u0131n\u0131 detayl\u0131 bir \u015fekilde g\u00f6rebiliyoruz.\n",
    "\n",
    "  - Referans Noktas\u0131 (Baseline): Mavi \u00e7izgi ile g\u00f6steriliyor. Herhangi bir iyile\u015ftirme veya filtreleme uygulanmam\u0131\u015f ham verilerin mesafe hatas\u0131n\u0131 temsil ediyor.\n",
    "\n",
    "  - WLS Y\u00f6ntemi: Turuncu \u00e7izgi ile g\u00f6steriliyor. A\u011f\u0131rl\u0131kl\u0131 en k\u00fc\u00e7\u00fck kareler (Weighted Least Squares) y\u00f6ntemi ile iyile\u015ftirilmi\u015f tahminler i\u00e7eriyor.\n",
    "\n",
    "  - Kalman Filtresi: Ye\u015fil \u00e7izgi ile g\u00f6steriliyor. WLS tahminlerini Kalman filtresiyle daha da iyile\u015ftiriyor.\n",
    "\n",
    "Baseline ve WLS y\u00f6nteminde g\u00f6zlenen ani s\u0131\u00e7ramalar, GNSS \u00f6l\u00e7\u00fcmlerindeki g\u00fcr\u00fclt\u00fc ve ayk\u0131r\u0131 de\u011ferlerden kaynaklan\u0131yor \u015feklinde bir yorumda bulunabiliriz. Ancak Kalman filtresi ile bu s\u0131\u00e7ramalar\u0131 etkin bir \u015fekilde filtreleyerek en iyi skoru almaya daha da yakla\u015f\u0131yoruz.\n",
    "\n",
    "WLS y\u00f6ntemi, ham veriye g\u00f6re bir iyile\u015fme sa\u011fl\u0131yor ancak ayk\u0131r\u0131 de\u011ferlere duyarl\u0131l\u0131\u011f\u0131 nedeniyle baz\u0131 veri noktalar\u0131nda y\u00fcksek hata g\u00f6steriyor. Kalman filtresinin eklenmesiyle hatalar daha d\u00fczenli ve tutarl\u0131 hale gelmi\u015f.\n",
    "<br></br>\n",
    "\n",
    "- \u0130kinci Grafik\n",
    "\n",
    "Bu grafikte, tahmin etti\u011fimiz h\u0131zlar ile ger\u00e7ek h\u0131zlar aras\u0131ndaki fark\u0131n olduk\u00e7a d\u00fc\u015f\u00fck ve tutarl\u0131 oldu\u011fu g\u00f6r\u00fcn\u00fcyor. Bu, da sistemimizin genel olarak g\u00fcvenilir bir \u015fekilde \u00e7al\u0131\u015ft\u0131\u011f\u0131n\u0131 destekliyor.\n",
    "\n",
    "ELde etti\u011fimiz 0.1265'lik bir RMSE de\u011feri de tahminlerin b\u00fcy\u00fck oranda do\u011fru oldu\u011funu destekliyor.\n",
    "\n",
    "Zaman zaman grafikte ani y\u00fckseli\u015fler oldu\u011funu g\u00f6zlemleyebiliriz. Bunun sebeplerini basit\u00e7e \u015fu \u015fekilde a\u00e7\u0131klayabiliriz:\n",
    "  - GPS sinyallerindeki kay\u0131plar (a\u011fa\u00e7l\u0131k yerler, y\u00fcksek binalar)\n",
    "  - Arac\u0131n h\u0131z\u0131ndaki ani de\u011fi\u015fimler\n",
    "  - Arac\u0131n ani manevralar\u0131\n",
    "\n",
    "  Bu hatalar\u0131 azaltmak i\u00e7in zaten Kalman Filtresi , WLS gibi y\u00f6ntemler ayr\u0131ca interpolasyon gibi eksik verileri doldurma gibi \u00f6n i\u015fleme uygulamalar\u0131 yapm\u0131\u015ft\u0131k. Ancak modelin do\u011frulu\u011funu daha da art\u0131rmak i\u00e7in LSTM, ANN , RNN gibi makine ve derin \u00f6\u011frenme algoritmalar\u0131 da kullanabiliriz.\n"
   ],
   "metadata": {
    "id": "5UZNPvcBgeAV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Skorlar\u0131m\u0131z\u0131 g\u00f6rselle\u015ftirerek mesafe hatas\u0131n\u0131 g\u00f6sterelim\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.title('Mesafe hatas\u0131')\n",
    "plt.xlabel('Zaman [saniye]')\n",
    "plt.ylabel('Mesafe hatas\u0131 [metre]')\n",
    "plt.plot(vd_bl, label=f'Referans Noktas\u0131 (Baseline) Skoru: {score_bl:.4f} m')\n",
    "plt.plot(vd_wls, label=f'WLS Y\u00f6ntemi Skoru: {score_wls:.4f} m')\n",
    "plt.plot(vd_kf, label=f'WLS Y\u00f6ntemi Skoru + Kalman Filtresi skoru: {score_kf:.4f} m')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.ylim([0, 10])\n",
    "\n",
    "# H\u0131z\u0131n hatas\u0131n\u0131 hesaplayal\u0131m\n",
    "speed_wls = np.linalg.norm(v_wls[:, :3], axis=1)  # 4. k\u0131s\u0131mda olu\u015fturdu\u011fumuz ve h\u0131z tahminlerini tuttu\u011fumuz v_wls matrisinin ilk 3 s\u00fctununuu alarak h\u0131z bile\u015fenlerini tutuyoruz (xyz)\n",
    "                                                  # np.linalg.norm: her bir vekt\u00f6r\u00fcn b\u00fcy\u00fckl\u00fc\u011f\u00fcn\u00fc (normunu) hesaplayacak. Burada, \u00fc\u00e7 boyutlu h\u0131z vekt\u00f6r\u00fcn\u00fcn b\u00fcy\u00fckl\u00fc\u011f\u00fcn\u00fc hesaplanarak skaler bir h\u0131z de\u011ferine d\u00f6n\u00fc\u015ft\u00fcrece\u011fiz.\n",
    "speed_gt = gt_df['SpeedMps'].to_numpy() # ger\u00e7ek h\u0131z verilerimizi tutuyoruz\n",
    "speed_rmse = np.sqrt(np.sum((speed_wls-speed_gt)**2)/len(speed_gt)) # ilk ba\u015fta tuttu\u011fumuz tahmini verilerle ikinci olarak tutut\u011fumuz ger\u00e7ek de\u011ferler aras\u0131ndaki fark\u0131m\u0131z\n",
    "\n",
    "# Hesaplad\u0131\u011f\u0131m\u0131z h\u0131z hatas\u0131n\u0131 g\u00f6rselle\u015ftirelim\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.title('H\u0131z hatas\u0131')\n",
    "plt.xlabel('Zaman [saniye]')\n",
    "plt.ylabel('H\u0131z Hatas\u0131 [m/s]')\n",
    "plt.plot(speed_wls - speed_gt, label=f'H\u0131z Hatas\u0131n\u0131n En K\u00fc\u00e7\u00fck Kareler Hata Oran\u0131 (RMSE): {speed_rmse:.4f} m')\n",
    "plt.legend()\n",
    "plt.grid()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "y_p3QHpygeXX",
    "outputId": "dbe900d7-ed63-4ccd-ab42-cd6517631e36"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 12- WGS Koordinat Sisteminden UTM Kooridinat Sistemine D\u00f6n\u00fc\u015f\u00fcm\n",
    "\n",
    "Bu fonksiyon ile birlikte daha \u00f6nce kulland\u0131\u011f\u0131m\u0131z WGS84 koordinat sistemi (d\u00fcnya genelinde kullan\u0131lan enlem-boylam tabanl\u0131 sistem) ile ifade edilen co\u011frafi konumlar\u0131, UTM (Universal Transverse Mercator) koordinat sistemine d\u00f6n\u00fc\u015ft\u00fcrece\u011fiz. Bunu yapamm\u0131zdaki amac\u0131m\u0131z\u0131 \u015fu \u015fekilde a\u00e7\u0131klayabiliriz:\n",
    "\n",
    "- WGS84, k\u00fcresel bir alan\u0131 refarans al\u0131rken UTM, d\u00fczlemsel alanlar\u0131 referans al\u0131r. Yani d\u00fcnya y\u00fczeyini b\u00f6lgelere ay\u0131r\u0131r ve her b\u00f6kge i\u00e7in d\u00fczlem koordinatlar\u0131 sa\u011flar. Bu da daha hassas mesafe ve alan hesaplamas\u0131 yapmam\u0131z\u0131 sa\u011flar.\n",
    "\n",
    "UTM, d\u00fcnyay\u0131 60 adet 6 derecelik dilime (boylama) b\u00f6ler. Bu dilimler kuzey ve g\u00fcney yar\u0131mk\u00fcreye g\u00f6re farkl\u0131 EPSG kodlar\u0131 ile ifade edilecek:\n",
    "- Kuzey yar\u0131mk\u00fcre i\u00e7in kodlar 326XX\n",
    "- G\u00fcney yar\u0131mk\u00fcre i\u00e7in kodlar 327XX\n",
    "\n",
    "  \u00d6rne\u011fin:\n",
    "  - (lon=30, lat=40) i\u00e7in 32636 d\u00f6necek. (kuzey yar\u0131m k\u00fcrede - 326xx oldu\u011funu anlayabiliriz)\n",
    "  - (lon=-70, lat=-20) i\u00e7in 32719 d\u00f6necek. (g\u00fcney yar\u0131m k\u00fcrede - 327xx oldu\u011funu anlayabiliriz)"
   ],
   "metadata": {
    "id": "0Ivt0L7DB2Bw"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def convert_wgs_to_utm(lon, lat):\n",
    "    utm_band = str((math.floor((lon + 180) / 6 ) % 60) + 1)\n",
    "    if len(utm_band) == 1:\n",
    "        utm_band = '0'+utm_band\n",
    "    if lat >= 0:\n",
    "        epsg_code = '326' + utm_band\n",
    "    else:\n",
    "        epsg_code = '327' + utm_band\n",
    "    return epsg_code"
   ],
   "metadata": {
    "id": "1M7gkud6B2Sd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 13- Ger\u00e7ek Veri K\u00fcmemizle Olu\u015fturdu\u011fumuz Veri K\u00fcmelerininin  (llh_bl, llh_wls, llh_kf) Birle\u015ftirilmesi"
   ],
   "metadata": {
    "id": "A89rRhMXG0ml"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Hem baseline hem wls hem de kalman filtresi ile olu\u015fturdu\u011fumuz df'lerimizden enlem , boylam ve hata(g\u00fcr\u00fclt\u00fc) s\u00fctunlar\u0131 i\u00e7eren df'ler olu\u015fturaca\u011f\u0131z\n",
    "llh_bl_df = pd.DataFrame(llh_bl)\n",
    "llh_bl_df.columns = ['lat', 'lon', 'Noise']\n",
    "\n",
    "llh_wls_df = pd.DataFrame(llh_wls)\n",
    "llh_wls_df.columns = ['lat', 'lon', 'Noise']\n",
    "\n",
    "llh_kf_df = pd.DataFrame(llh_kf)\n",
    "llh_kf_df.columns = ['lat', 'lon', 'Noise']\n",
    "\n",
    "# Ground Truth yani ger\u00e7ek verilerin oldu\u011fu veri setimizdeki EnlemDerecesi ve Boylam Derecesi s\u00fctunlar\u0131n\u0131n ismini de\u011fi\u015ftrdik\n",
    "gt_df.rename(columns = {'LatitudeDegrees':'lat', 'LongitudeDegrees':'lon'}, inplace = True)\n",
    "\n",
    "\n",
    "all_tracks = pd.concat([gt_df, llh_bl_df, llh_wls_df, llh_kf_df]) # Daha sonra ilk olarak \u00fcstte d\u00fczenledi\u011fimiz 4 df'i birle\u015ftirdik\n",
    "all_tracks  =all_tracks[['lat', 'lon']]   # bu birle\u015ftirdi\u011fimiz df'te sadece enlem ve boylam verilerini tuttuk\n",
    "\n",
    "# Son olu\u015fturdu\u011fumuz all_tracks df'imizde hangi verinin hangi y\u00f6ntemden geldi\u011fini anlamak i\u00e7in \"Name\" ad\u0131nda bir s\u00fctun olu\u015fturaca\u011f\u0131z\n",
    "all_tracks['Name'] = np.repeat(['gt','bl', 'wls','kf'],gt_df.shape[0])\n",
    "all_tracks"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "SnyaYZ3IHCEQ",
    "outputId": "32bb521c-f258-4e88-c849-89ca0a561e0e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Yukar\u0131da olu\u015ftrudu\u011fumuz total veri k\u00fcmesini g\u00f6rselle\u015ftirmeye \u00e7al\u0131\u015fal\u0131m\n",
    "\n",
    "fig = px.line_mapbox(all_tracks,lat=\"lat\",  lon=\"lon\",  color=\"Name\",  labels={\"Name\": \"Veri Kayna\u011f\u0131\"},zoom=12, center={\"lat\": 37.45 , \"lon\": -122.27},  height=600, width=1000)\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "fig.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "Lf0kQwt0HSUS",
    "outputId": "2ce7a958-bbb0-4fd3-e945-f8bf11c72577"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 14 - Veri Setine Uzakl\u0131k , H\u0131z , A\u00e7\u0131, E\u011fiklik ve \u0130vme \u00d6zelliklerinin Eklenmesi\n",
    "\n",
    "\n",
    "Bu fonksiyon ile birlikte bir DataFrame'e (biz llh_kf_Df'i kullanaca\u011f\u0131z \u00e7\u00fcnk\u00fc en iyi sonu\u00e7 orda) uzakl\u0131k, h\u0131z, a\u00e7\u0131, e\u011frilik (curvature) gibi baz\u0131  \u00f6zellikleri ekleyecek.\n",
    "\n",
    "Burada \"e\u011frilik\"ten kast\u0131m\u0131z yoldun d\u00fczl\u00fc\u011f\u00fc ya da k\u0131vr\u0131kl\u0131\u011f\u0131d\u0131r. Yol ne kadar d\u00fczse e\u011frilik s\u0131f\u0131ra yak\u0131n olacakt\u0131r.\n",
    "\n",
    "Bu fonksiyonnu rota optimizasyonu gibi i\u015flemlerde kullanabilece\u011fiz. \u00d6rne\u011fin, ara\u00e7lar\u0131n hareket verilerini analiz etmek, rotadaki keskin d\u00f6n\u00fc\u015fleri veya h\u0131z de\u011fi\u015fimlerini belirlemek i\u00e7in kullanaca\u011f\u0131z.\n",
    "\n",
    "(X ->t\u00fcrevi: v ->t\u00fcrevi: a)\n",
    "\n",
    "E\u011frilik Form\u00fcl\u00fc: ![image.png](data:image/png;base64,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)"
   ],
   "metadata": {
    "id": "jimOa4kk5sRt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def add_distance_speed_angle_curv_diff(df):\n",
    "    # \u0130lk Ba\u015fta Yap\u0131lmas\u0131 Gerekli D\u00f6n\u00fc\u015f\u00fcm\n",
    "    # Normalde GPS koordinatlar\u0131 (en-boy)  k\u00fcrsel koor. sis olan WGS84'te ifade edilir ancak e\u011frilik , h\u0131z gibi hesaplamak istedi\u011fimiz metrikler d\u00fczlemsel koor. sis.de daha kolay hesaplan\u0131r...\n",
    "    # ... Bundan dolay\u0131 daha \u00f6nce de yapt\u0131\u011f\u0131m\u0131z gibi WGS84(epsg:4326) sisteminden UTM'ye ge\u00e7i\u015f yapmam\u0131z gerekiyor\n",
    "    utm_code = convert_wgs_to_utm(df['lon'].mean(), df['lat'].mean())   # enlem ve boylam\u0131n ortalamas\u0131na g\u00f6re bir utm kodu olu\u015fturduk (wgs koor. sisteminden utm'ye ge\u00e7i\u015f yapt\u0131k)\n",
    "    crs_wgs = proj.Proj(init='epsg:4326') # WGS84 koor sis. tan\u0131mlad\u0131k\n",
    "    crs_utm = proj.Proj(init='epsg:{0}'.format(utm_code)) # d\u00f6n\u00fc\u015f\u00fcm\u00fc sa\u011flad\u0131k\n",
    "    x, y = np.multiply(proj.transform(crs_wgs, crs_utm, df['lon'], df['lat']),0.001)  # metre yerine kilometre cinsine \u00e7evirece\u011fimiz i\u00e7in 0.001 ile \u00e7arpt\u0131k\n",
    "\n",
    "\n",
    "\n",
    "    # H\u0131z(vekt\u00f6rel) ve S\u00fcrat(skaler) Hesaplamas\u0131\n",
    "    # np.gradient ile birlikte x ve y koordinatlar\u0131n\u0131n zamana g\u00f6re t\u00fcrevleri (de\u011fi\u015fim oranlar\u0131 , e\u011fimlerini) alaca\u011f\u0131z.\n",
    "    x_t = np.gradient(x)  # x eksenindeki de\u011fi\u015fim oran\u0131.\n",
    "    y_t = np.gradient(y)  # y eksenindeki de\u011fi\u015fim oran\u0131.\n",
    "\n",
    "    vel = np.array([ [x_t[i], y_t[i]] for i in range(x_t.size)])  # h\u0131z vekt\u00f6rel oldu\u011fu i\u00e7in h\u0131z vekt\u00f6r\u00fcn\u00fc olu\u015fturduk\n",
    "\n",
    "    speed = np.sqrt(x_t * x_t + y_t * y_t)  # x ile y eksenindeki t\u00fcrevlerin karesinin toplam\u0131n\u0131n karek\u00f6k\u00fc al\u0131narak toplam h\u0131z\u0131 hesaplad\u0131k (pisagor).\n",
    "\n",
    "    tangent = np.array([1/speed] * 2).transpose() * vel   # h\u0131z\u0131n y\u00f6n\u00fcn\u00fc hesaplamak i\u00e7in de te\u011fet vekt\u00f6r\u00fc olu\u015fturduk\n",
    "\n",
    "\n",
    "\n",
    "    # E\u011frilik Hesaplanmas\u0131 (Yolun d\u00fczl\u00fc\u011f\u00fc ya da virajl\u0131l\u0131\u011f\u0131)\n",
    "    ss_t = np.gradient(speed) # h\u0131z\u0131n zamana g\u00f6re t\u00fcrevi yani ivme\n",
    "    xx_t = np.gradient(x_t)   # xx_t asl\u0131nda x'in 2. derece t\u00fcrevi ya da x_t'nin t\u00fcrevi YAN\u0130 # x ekseninin ikinci t\u00fcrevi\n",
    "    yy_t = np.gradient(y_t)   # y ekseninin ikinci t\u00fcrevi\n",
    "\n",
    "    curvature = (xx_t * y_t - x_t * yy_t) / (x_t * x_t + y_t * y_t)**1.5  # e\u011frilik form\u011fl\u011f kullanarak e\u011frili\u011fi hesaplad\u0131k\n",
    "    xxyy = np.sqrt(xx_t * xx_t + yy_t * yy_t) # bu e\u011frilik de\u011fi\u015fiminin b\u00fcy\u00fckl\u00fc\u011f\u00fcn\u00fc hesapl\u0131yoruz\n",
    "\n",
    "\n",
    "\n",
    "    # \u0130vme Hesaplanmas\u0131\n",
    "    tangent_x = tangent[:, 0] # x ekseninin e\u011fimi (tanjant\u0131)\n",
    "    tangent_y = tangent[:, 1] # y ekseninin e\u011fimi\n",
    "\n",
    "    # tangent_x = yolun t\u00fcrevi = h\u0131z. Burda da tangent_x'in t\u00fcrevinin t\u00fcrevini alarak ivmeyi bulaca\u011f\u0131z yani ivmeyi\n",
    "    deriv_tangent_x = np.gradient(tangent_x)  # x eksenindeki ivmesi\n",
    "    deriv_tangent_y = np.gradient(tangent_y)  # y eksenindeki ivmesi\n",
    "\n",
    "    # x eksenindeki ivme ile y eksenindeki ivmeyi birle\u015ftirece\u011fiz\n",
    "    # Yani, her bir zaman ad\u0131m\u0131ndaki de\u011fi\u015fim \u015fu \u015fekilde bir vekt\u00f6r olarak ifade edece\u011fiz: dT_dt=[deriv_tangent_x,deriv_tangent_y]\n",
    "    dT_dt = np.array([ [deriv_tangent_x[i], deriv_tangent_y[i]] for i in range(deriv_tangent_x.size)])\n",
    "\n",
    "    length_dT_dt = np.sqrt(deriv_tangent_x * deriv_tangent_x + deriv_tangent_y * deriv_tangent_y) # \u00fcstteki dT_dt vekt\u00f6r\u00fcn\u00fcn b\u00fcy\u00fckl\u00fc\u011f\u00fcn\u00fc hesaplad\u0131k. Yani ivmenin b\u00fcy\u00fckl\u00fc\u011f\u00fcn\u00fc hesaplad\u0131k\n",
    "\n",
    "    normal = np.array([1/length_dT_dt] * 2).transpose() * dT_dt  # Normal vekt\u00f6r\u00fcm\u00fcz =  dT_dt/|dT_dt|\n",
    "\n",
    "    t_component = np.array([ss_t] * 2).transpose()  # Tanjant bile\u015fenizimiz = ss_t * tanjant y\u00f6n vekt\u00f6r\u00fc. Hareket y\u00f6n\u00fcndeki h\u0131z de\u011fi\u015fimini temsil edecek\n",
    "                                                    # ss_t, h\u0131z\u0131n zamana g\u00f6re t\u00fcreviydi (ivme)\n",
    "\n",
    "    n_component = np.array([curvature*ss_t * ss_t] * 2).transpose()   # Normal bile\u015fenimiz(ivmenin normal y\u00f6n\u00fcndeki bile\u015feni) =  curvate * ss_t * ss_t * normal vekt\u00f6r.\n",
    "                                                                      # Hareketin e\u011frilik veya d\u00f6nme kaynakl\u0131 bile\u015feni\n",
    "\n",
    "    # TOPLAM \u0130vme\n",
    "    accel = t_component * tangent + n_component * normal\n",
    "\n",
    "\n",
    "    # Olu\u015fturdu\u011fumuz bile\u015fenleri kullanmak istedi\u011fimiz df'e s\u00fctun olarak ekleyelim\n",
    "    df['curve']= curvature\n",
    "    df['speed']= speed\n",
    "    df['acc'] = np.linalg.norm(accel, axis=1)\n",
    "    df['gas']= ss_t\n",
    "    df['dir_x'] = x_t / speed\n",
    "    df['dir_y'] = y_t / speed\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "id": "QTJaliMnIYmC"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#15- H\u0131z , A\u00e7\u0131 , E\u011fiklik ve \u0130vme \u00d6zelliklerinin Veri Setine Entegresi Ve G\u00f6rselle\u015ftirmeler"
   ],
   "metadata": {
    "id": "vg_OlUEZgH3m"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Yukar\u0131da olu\u015fturdu\u011fumuz add_distance_speed_angle_curv_diff fonksiyonumuzu llh_kf veri setimize entegre edelim.\n",
    "# Bu sayede H\u0131z, \u0130vme, H\u0131z De\u011fi\u015fim Oran\u0131 , E\u011frilik ve Y\u00f6n gibi bile\u015fenlerle veri setimizi zenginle\u015ftirelim\n",
    "\n",
    "llh_kf_df = pd.DataFrame(llh_kf)\n",
    "llh_kf_df.columns = ['lat', 'lon', 'Noise'] # s\u00fctnlar\u0131m\u0131z ayn\u0131 \u015fekilde eylem, boylam ve g\u00fcr\u00fclt\u00fc olacak\n",
    "llh_kf_df = add_distance_speed_angle_curv_diff(llh_kf_df) # add_distance_speed_angle_curv_diff fonksiyonumuzu \u00e7al\u0131\u015ft\u0131rarak yeni  llh_kf_df veri setimizi olu\u015fturduk"
   ],
   "metadata": {
    "collapsed": true,
    "id": "VN0at_FWgII5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# H\u0131z verimize bir medyan filtresi uygulayaca\u011f\u0131z signal.medfilt ile birlikte. medlift'in de\u011ferini 3 verdik. Bu da her 3 noktan\u0131n ortanca de\u011ferini alarak veriyi d\u00fczeltmesi anlam\u0131na gelecek\n",
    "# Bu sayede g\u00fcr\u00fclt\u00fcy\u00fc azaltacak, h\u0131zdaki ani art\u0131\u015f ve d\u00fc\u015f\u00fc\u015fleri filtrelemei\u015f olaca\u011f\u0131z. Bu sayede grafikteki dalgalanmalar daha d\u00fczenli ve tutarl\u0131 hale gelerek analizimiz daha anlaml\u0131 olacak\n",
    "speed = signal.medfilt(llh_kf_df['speed'],3)\n",
    "\n",
    "llh_kf_df['speed_filt'] = speed   # Filtreden ge\u00e7irdi\u011fimiz h\u0131z verisini \"speed;_filt\" ad\u0131nda yeni bir s\u00fctuna atad\u0131k\n",
    "\n",
    "\n",
    "# Orijinal H\u0131z\u0131n grafi\u011fi\n",
    "# plt.figure(5, figsize=(15, 3))\n",
    "# plt.title(\"Orijinal H\u0131z\")\n",
    "# plt.xlabel(\"Zaman [sn]\")\n",
    "# plt.plot(range(llh_kf_df.shape[0]), llh_kf_df['speed'], label=\"Orijinal H\u0131z\")\n",
    "# plt.legend()\n",
    "\n",
    "# Yukar\u0131da yapt\u0131\u011f\u0131m\u0131z filtreleme sonucu H\u0131z\u0131n grafi\u011fi\n",
    "plt.figure(6, figsize=(15, 3))\n",
    "plt.title(\"(Filtrelenmi\u015f) H\u0131z\")\n",
    "plt.xlabel(\"Zaman [sn]\")\n",
    "plt.ylabel(\"H\u0131z De\u011ferleri [m/sn]\")\n",
    "plt.plot(range(llh_kf_df.shape[0]), llh_kf_df['speed_filt'], label=\"Filtrelenmi\u015f H\u0131z\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "# YORUMLAMA\n",
    "  # Araban\u0131n hareketinin ba\u015flad\u0131\u011f\u0131 ve bitti\u011fi zaman aral\u0131klar\u0131n\u0131 net bir \u015fekilde g\u00f6rebiliyoruz (\u00f6rne\u011fin h\u0131z\u0131n 0 oldu\u011fu noktalar)\n",
    "  # H\u0131zdaki de\u011fi\u015fimlere bakarak h\u0131zlanma ve yava\u015flama b\u00f6lgelerini bel\u011firleyebiliriz."
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "_KiJ2tNanJsd",
    "outputId": "43c70c11-963f-4fb1-a102-acbfa1a62fe8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# H\u0131z'da yapt\u0131\u011f\u0131m\u0131z i\u015flemin ayn\u0131s\u0131n\u0131 yap\u0131yoruz. \u0130vmede de filtreleme i\u015flemi yaparak g\u00fcr\u00fclt\u00fcden ar\u0131nd\u0131rmay\u0131 ama\u00e7l\u0131yoruz\n",
    "acc = signal.medfilt(llh_kf_df['acc'],3)\n",
    "\n",
    "llh_kf_df['acc_filt'] = acc   # filtrelenmi\u015f veriyi \"acc_filt\" ad\u0131nda bir s\u00fctuna at\u0131yoruz\n",
    "\n",
    "# Orijinal \u0130vmenin grafi\u011fi\n",
    "plt.figure(1, figsize=(15,3))\n",
    "plt.title(\"Orijinal \u0130vme\")\n",
    "plt.xlabel(\"Zaman [sn]\")\n",
    "plt.plot(range(llh_kf_df.shape[0]), llh_kf_df['acc'])\n",
    "plt.legend()\n",
    "\n",
    "# Filtelenmi\u015f \u0130vmenin grafi\u011fi\n",
    "plt.figure(2, figsize=(15,3))\n",
    "plt.title(\"(Filtrelenmi\u015f)\u0130vme\")\n",
    "plt.xlabel(\"Zaman [sn]\")\n",
    "plt.plot(range(llh_kf_df.shape[0]), llh_kf_df['acc_filt'])\n",
    "\n",
    "\n",
    "\n",
    "# YORUMLAMA:\n",
    "  # Yukar\u0131daki grafikte g\u00f6rd\u00fc\u011f\u00fcm\u00fcz gibi orijinal ivme grafi\u011finde ani zirveler ve d\u00fczensiz de\u011fi\u015fimler var. Biz bunu gidermek i\u00e7in medyan filter kulland\u0131k\n",
    "  # \u0130kinci grafikte g\u00f6rd\u00fc\u011f\u00fcm\u00fcz gibi filtrelememiz i\u015fe yaram\u0131\u015f ve g\u00fcr\u00fclt\u00fc oran\u0131m\u0131z azalm\u0131\u015f. Daha d\u00fczenli ve anlaml\u0131 bir grafik elde ettik. Dolay\u0131s\u0131yla daha analiz edilebilir."
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 745
    },
    "id": "FRiUaJeznL9k",
    "outputId": "5e99b883-cc7b-4742-a0b0-53c52a710a74"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# H\u0131z'da yapt\u0131\u011f\u0131m\u0131z i\u015flemin ayn\u0131s\u0131n\u0131 yap\u0131yoruz. H\u0131z de\u011fi\u015fiminde de filtreleme i\u015flemi yaparak g\u00fcr\u00fclt\u00fcden ar\u0131nd\u0131rmay\u0131 ama\u00e7l\u0131yoruz\n",
    "gas = signal.medfilt(llh_kf_df['gas'],3)\n",
    "\n",
    "llh_kf_df['gas_filt'] = gas  # filtrelenmi\u015f veriyi \"gas_filt\" ad\u0131nda bir s\u00fctuna at\u0131yoruz\n",
    "\n",
    "# Orijinal H\u0131z De\u011fi\u015fim Oran\u0131 grafi\u011fi\n",
    "# plt.figure(7, figsize=(15,3))\n",
    "# plt.title(\"Orijinal H\u0131z De\u011fi\u015fim Oran\u0131\")\n",
    "# plt.xlabel(\"Zaman [sn]\")\n",
    "# plt.plot(range(llh_kf_df.shape[0]), llh_kf_df['gas'])\n",
    "\n",
    "# Filtrelenmi\u015f H\u0131z De\u011fi\u015fim Oran\u0131 grafi\u011fi\n",
    "plt.figure(8, figsize=(15,3))\n",
    "plt.title(\"(Filtrelenmi\u015f) H\u0131z De\u011fi\u015fim Oran\u0131\")\n",
    "plt.xlabel(\"Zaman [sn]\")\n",
    "plt.plot(range(llh_kf_df.shape[0]), llh_kf_df['gas_filt'])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "id": "DAu5VpvVnQJ_",
    "outputId": "18a98b49-8fbd-4679-acc3-7ee9ffb4d3f8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "crv = llh_kf_df['curve']\n",
    "\n",
    "# E\u011frilik de\u011ferleri a\u015f\u0131r\u0131 y\u00fcksek ya da d\u00fc\u015f\u00fck olanlar\u0131 s\u0131n\u0131rland\u0131raca\u011f\u0131z. Burada 5 ve -5 de\u011ferlerini standart sapmaya g\u00f6re verdik. Bu sayede a\u015f\u0131r\u0131 de\u011ferlerin analizini, filtrelemesini ger\u00e7ekle\u015ftirdik\n",
    "crv[crv>10]=5\n",
    "crv[crv<-10]=-5\n",
    "\n",
    "# H\u0131z'da yapt\u0131\u011f\u0131m\u0131z i\u015flemin ayn\u0131s\u0131n\u0131 yap\u0131yoruz. E\u011frilikde de filtreleme i\u015flemi yaparak g\u00fcr\u00fclt\u00fcden ar\u0131nd\u0131rmay\u0131 ama\u00e7l\u0131yoruz. Her 3 de\u011ferin ortanca de\u011ferini al\u0131yoruz\n",
    "crv = signal.medfilt(crv,3)\n",
    "\n",
    "# Sigmoid fonksiyonu uygulad\u0131k. Buradaki amacam\u0131z: e\u011frilik verisini normalize ederek 0-1 aras\u0131na s\u0131k\u0131\u015ft\u0131rmak. Bu sayede daha tutarl\u0131 sonu\u00e7lar elde etmek\n",
    "crv = 1/(1+np.exp(-crv))\n",
    "\n",
    "# \u0130kinci bir filtreleme yap\u0131yoruz.\n",
    "  # \u0130lk filtreleme genellikle k\u00fc\u00e7\u00fck ve h\u0131zl\u0131 de\u011fi\u015fimlerin etkisini azaltacak\n",
    "  # \u0130kinci filtrelemede Her 9 de\u011ferin ortanca de\u011ferini alarak k\u0131sa vadeli dalgalanmalar\u0131 iyice d\u00fczeltecek. Sigmoid'ten kaynaklanan olas\u0131 dalgalanmalar\u0131 giderecek\n",
    "crv = signal.medfilt(crv, 9)\n",
    "\n",
    "llh_kf_df['crv_filt'] = crv   #  filtrelenmi\u015f veriyi \"crv_filt\" ad\u0131nda bir s\u00fctuna at\u0131yoruz\n",
    "\n",
    "# Orijinal E\u011frilik grafi\u011fi\n",
    "plt.figure(3, figsize=(15,3))\n",
    "plt.title(\"Orijinal E\u011frilik\")\n",
    "plt.xlabel(\"Zaman [sn]\")\n",
    "plt.plot(range(llh_kf_df.shape[0]), llh_kf_df['curve'])\n",
    "\n",
    "# Filtrelenmi\u015f E\u011frilik grafi\u011fi\n",
    "plt.figure(4, figsize=(15,3))\n",
    "plt.title(\"(Filtrelenmi\u015f) E\u011frilik\")\n",
    "plt.xlabel(\"Zaman [sn]\")\n",
    "plt.plot(range(llh_kf_df.shape[0]), llh_kf_df['crv_filt'])\n",
    "\n",
    "\n",
    "\n",
    "# YORUMLAMA\n",
    "  # Orijinal grafikte verinin g\u00fcr\u00fclt\u00fcden etkilendi\u011fi \u00e7ok bariz g\u00f6r\u00fcn\u00fcyor.\n",
    "  # G\u00fcr\u00fclt\u00fcleri b\u00fcy\u00fck \u00f6l\u00e7\u00fcde azaltt\u0131\u011f\u0131m\u0131z\u0131 g\u00f6r\u00fcyoruz Daha d\u00fczenli ve analiz edilbilir bir veri seti elde ettik"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "id": "QBC6fOPAnQd9",
    "outputId": "a8944d8c-2c69-479e-a29a-79a4eb0bebe7"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Y\u00f6n\n",
    "\n",
    "plt.figure(10, figsize=(15,5))\n",
    "plt.title(\"Y\u00f6n - X ve Y Y\u00f6n\u00fcndeki\")\n",
    "plt.xlabel(\"Zaman [sn]\")\n",
    "plt.plot(range(llh_kf_df.shape[0]), llh_kf_df['dir_x'] , label = \"X y\u00f6n\u00fcndeki h\u0131z\") # 14. b\u00f6l\u00fcmde olu\u015ftrudu\u011fumuz x y\u00f6n\u00fcndeki hareket\n",
    "plt.plot(range(llh_kf_df.shape[0]), llh_kf_df['dir_y'] , label = \"Y y\u00f6n\u00fcndeki h\u0131z\") # 14. b\u00f6l\u00fcmde olu\u015ftrudu\u011fumuz y y\u00f6n\u00fcndeki hareket\n",
    "plt.legend()\n",
    "\n",
    "# Yorumlama:\n",
    "  # E\u011fer \u00e7izgi pozitifse, o eksende ileri y\u00f6nde hareket oldu\u011fu anlam\u0131na gelir.\n",
    "  # E\u011fer \u00e7izgi negatifse, ters y\u00f6nde hareket oldu\u011fu anlam\u0131na gelir.\n",
    "  # \u00c7izginin s\u0131f\u0131ra yak\u0131n oldu\u011fu yerlerde, o eksendeki hareketin minimal oldu\u011fu \u00e7\u0131kar\u0131labilir."
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "r_RqKZM1nUQ_",
    "outputId": "7e6ca222-0609-48d5-9236-b39e96e4c09e"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "* G\u00f6rselle\u015ftirmeler"
   ],
   "metadata": {
    "id": "Sg83KwzHnUqB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# E\u011frilik de\u011ferlerimizi g\u00f6rselle\u015ftirelim\n",
    "fig = px.scatter_mapbox(llh_kf_df,\n",
    "                        lat=\"lat\",\n",
    "                        lon=\"lon\",\n",
    "                        color=\"crv_filt\",\n",
    "                        zoom=12,\n",
    "                        center={\"lat\":37.45, \"lon\":-122.27},\n",
    "                        height=600,\n",
    "                        width=800)\n",
    "fig.update_layout(mapbox_style='open-street-map')\n",
    "fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "fig.show()\n",
    "\n",
    "# Yorumlama:\n",
    "  # Her bir nokta, hareketin bir enlem ve boylam koordinat\u0131na kar\u015f\u0131l\u0131k gelir.\n",
    "  # Noktalar\u0131n renkleri, ilgili noktadaki e\u011frilik de\u011ferine g\u00f6re de\u011fi\u015fecek.\n",
    "    # sar\u0131-k\u0131rm\u0131z\u0131 renkler: Daha y\u00fcksek e\u011frilik (keskin d\u00f6n\u00fc\u015f - viraj).\n",
    "    # mavi-mor renkler: Daha d\u00fc\u015f\u00fck e\u011frilik (d\u00fcz yol).\n",
    "  # Bu \u00e7\u0131kt\u0131y\u0131 rota analizinde kullanabiliriz"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "jGpJ5on1gWxr",
    "outputId": "de3586c5-e26b-4245-ca86-09d9ae5b9f13"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# E\u011frilik ve \u0130vme De\u011ferlerini g\u00f6rselle\u015ftirelim katmanl\u0131 bir \u015fekilde. Bu sayade bunlar aras\u0131ndaki ili\u015fkiyi daha iyi anlayabiliriz\n",
    "\n",
    "# \u0130lk katman\u0131m\u0131z olan \u0130vme katman\u0131\n",
    "fig = go.Figure(go.Scattermapbox(lon=llh_kf_df['lon'],\\\n",
    "                                        lat=llh_kf_df['lat'],\\\n",
    "                                        marker= go.scattermapbox.Marker(size=6, showscale=True), opacity=0.6,\n",
    "                                        marker_color=llh_kf_df['acc_filt'], name = 'acceleration'))\n",
    "\n",
    "\n",
    "# \u0130kinci katman\u0131m\u0131z E\u011frilik katman\u0131\n",
    "fig.add_trace(go.Scattermapbox(lon=llh_kf_df['lon'],\\\n",
    "                                        lat=llh_kf_df['lat'],\\\n",
    "                                        marker= go.scattermapbox.Marker(size=6, showscale=True), opacity=0.6,\n",
    "                                        marker_color=llh_kf_df['crv_filt'], name = 'curvature'))\n",
    "\n",
    "\n",
    "# Noktalar\u0131n \u00fczerine geldi\u011fimizdeki hover bilgilerini ayarlayal\u0131m\n",
    "fig.update_traces(\n",
    "    showlegend=True,\n",
    "    hoverinfo='text',\n",
    "    text=[\n",
    "        f\"Lat: {lat}, Lon: {lon}, Acc: {acc:.4f}, Crv: {crv:.2f}\"\n",
    "        for lat, lon, acc, crv in zip(llh_kf_df['lat'], llh_kf_df['lon'], llh_kf_df['acc_filt'], llh_kf_df['crv_filt'])\n",
    "    ]\n",
    "    )\n",
    "\n",
    "\n",
    "# Sol tarafa katmanlar aras\u0131nda ge\u00e7i\u015fi kolayla\u015ft\u0131rmak ad\u0131na bir buton ekleyelim\n",
    "fig.update_layout(\n",
    "    updatemenus=[\n",
    "        dict(\n",
    "            buttons=[\n",
    "                dict(\n",
    "                    label=\"\u0130vme\",\n",
    "                    method=\"update\",\n",
    "                    args=[{\"visible\": [True, False]}, {\"title\": \"\u0130vme\"}]\n",
    "                ),\n",
    "                dict(\n",
    "                    label=\"E\u011frilik\",\n",
    "                    method=\"update\",\n",
    "                    args=[{\"visible\": [False, True]}, {\"title\": \"E\u011frilik\"}]\n",
    "                )\n",
    "            ],\n",
    "            direction=\"down\",\n",
    "            showactive=True\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Estetik g\u00f6r\u00fcn\u00fc\u015f ad\u0131na i\u015faret tablosunda g\u00fczelle\u015ftirmeler yapal\u0131m\n",
    "fig.update_layout(\n",
    "    legend=dict(\n",
    "        orientation=\"h\",       # Yatay d\u00fczen i\u00e7in\n",
    "        yanchor=\"bottom\",\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "        title_text=\"Renk Skalas\u0131\"\n",
    "    ),\n",
    "    margin=dict(r=0, t=30, l=0, b=0),\n",
    "    title=dict(\n",
    "        text=\"E\u011frilik ve \u0130vme De\u011ferlerinin G\u00f6rselle\u015ftirilmesi\",\n",
    "        x=0.5,\n",
    "        font=dict(size=18)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Haritam\u0131z\u0131n ayarlamalar\u0131n\u0131 yapal\u0131m\n",
    "fig.update_layout(\n",
    "    mapbox_style=\"carto-positron\",  # sade ve okunakl\u0131 bir g\u00f6r\u00fcn\u00fcm i\u00e7in bu stili kullan\u0131dk\n",
    "    autosize=True,\n",
    "    hovermode='closest',\n",
    "    mapbox=dict(\n",
    "        accesstoken=\"pk.eyJ1IjoibGF5YWxoYW1tYWQiLCJhIjoiY2wzbWd5ZWxjMDFqNDNmcWt5MzRzNHdlaCJ9.B04CAbFi5Llmk2B78EP6JQ\",\n",
    "        bearing=0,\n",
    "        center=dict(lat=37.45,lon= -122.27),\n",
    "        pitch=0,  # yatay bak\u0131\u015f a\u00e7\u0131s\u0131\n",
    "        zoom=12)\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# YORUMLAMA\n",
    "  # \u0130vme De\u011ferleri:\n",
    "    # \u0130vme de\u011ferleri, genellikle trafik \u0131\u015f\u0131klar\u0131 veya keskin d\u00f6n\u00fc\u015flerin yani virajlar\u0131n oldu\u011fu yerlerde daha y\u00fcksek olabilir.\n",
    "    # D\u00fc\u015f\u00fck ivme genellikle d\u00fcz yollarda veya sabit h\u0131zla gidilen b\u00f6lgelerde g\u00f6r\u00fclmesi beklenecek.\n",
    "\n",
    "  # E\u011frilik De\u011ferleri:\n",
    "    # Y\u00fcksek e\u011frilik (virajlar) genelde yollar\u0131n k\u0131vr\u0131ml\u0131 oldu\u011fu b\u00f6lgelerde g\u00f6zlemlenecek.\n",
    "    # D\u00fc\u015f\u00fck e\u011frilik (d\u00fcz yollar), otoyollar veya uzun d\u00fcz yollar boyunca g\u00f6zlemlenecek.\n",
    "    # E\u011frilik de\u011ferleri i\u00e7in yapt\u0131\u011f\u0131m\u0131z filtreleme i\u015flemleri, haritadaki g\u00fcr\u00fclt\u00fcy\u00fc azaltmam\u0131z\u0131 sa\u011flayacak.\n",
    "\n",
    "  # Bu grafik sayesinde:\n",
    "    # Y\u00fcksek e\u011frilik ve y\u00fcksek ivme bir aradaysa buralar kazalar\u0131n s\u0131k\u00e7a ya\u015fanabilece\u011fi b\u00f6lgeler olarak ia\u015faretlenebilir\n",
    "    # Ara\u00e7lar\u0131n h\u0131zlanma ve e\u011frilik de\u011ferlerine bakarak s\u00fcr\u00fc\u015f dinamikleri anla\u015f\u0131labilr (\u00f6rne\u011fin ivmelenme verileri trafik s\u0131k\u0131\u015f\u0131kl\u0131\u011f\u0131n\u0131 ya da ani h\u0131z de\u011fi\u015fimlerini g\u00f6sterebilir)\n",
    "    # Yolu tasarlayan ve trafikle ilgilenen m\u00fchendisleri, bu verileri kullanarak yol tasar\u0131mlar\u0131n\u0131 iyile\u015ftirebilir veya sorunlu b\u00f6lgeleri belirleyebilir\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "PHY7CBFZgZOI",
    "outputId": "1897642e-c3a6-4b19-e838-e9ab8cab0896"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# KULLANDI\u011eIMIZ VER\u0130 SET\u0130NDE BANDIRMA YA DA T\u00dcRK\u0130YE \u0130LE \u0130LG\u0130L\u0130 VER\u0130 BULUNMADI\u011eINDAN BANDIRMA \u0130LE \u0130LG\u0130L\u0130 B\u0130R TAHM\u0130NE BULUNAMIYORUZ\n",
    "\n",
    "fig = px.line_mapbox(all_tracks,lat=\"lat\",  lon=\"lon\",  color=\"Name\",  labels={\"Name\": \"Veri Kayna\u011f\u0131\"},zoom=12, center={\"lat\": 40.3506 , \"lon\": 27.9767},  height=600, width=1000)\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "fig.show()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "dRzhwDB3iSxr",
    "outputId": "a435e651-d0ce-4ca1-edd4-fdb1e07bd491"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#16- LSTM Uygulamak \u0130\u00e7in Veri Setinin Haz\u0131rlanmas\u0131\n",
    "\n",
    "Neden LSTM?\n",
    "\n",
    "- GNSS verileri genellikle zaman serisi format\u0131nda oldu\u011fu i\u00e7in, LSTM/GRU gibi tekrarlayan sinir a\u011flar\u0131 (RNN-based models), ge\u00e7mi\u015f bilgileri hat\u0131rlayarak daha isabetli tahminler yapabilir.\n",
    "- GPS sinyallerinin kayboldu\u011fu veya g\u00fcr\u00fclt\u00fcl\u00fc oldu\u011fu durumlarda, \u00f6nceki verilere dayanarak tahmin yapabilir."
   ],
   "metadata": {
    "id": "U2Fa1qUHzvV6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# DER\u0130N \u00d6\u011eRENMEYE SOKAB\u0130LMEK \u0130\u00c7\u0130N BA\u011eIMLI VE BA\u011eIMSIZ DE\u011e\u0130\u015eKENLER\u0130M\u0130Z\u0130 (x - y)  BEL\u0130RLEMEM\u0130Z GEREK\u0130YOR \u0130LK BA\u015eTA\n",
    "\n",
    "\n",
    "# llh_kf_df'den 'speed', 'curve', 'acc' ve 'gas' yani h\u0131z de\u011fi\u015fim oran\u0131 s\u00fctunlar\u0131n\u0131 \u00e7\u0131kar\u0131yoruz ve bunu X_raw ad\u0131nda yeni bir veri setinde tutuyoruz.\n",
    "# \u00c7\u00fcnk\u00fc bu s\u00fctunlar\u0131 tahmin i\u00e7in girdi olarak kullanmayaca\u011f\u0131z. Bunun yerine bir filtreledi\u011fimiz hallerini kullanaca\u011f\u0131z\n",
    "X_raw = llh_kf_df.drop(['speed','curve','acc','gas'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Modelin ge\u00e7mi\u015f ad\u0131mlar\u0131 dikkate alarak daha do\u011fru tahminler yapmas\u0131n\u0131 sa\u011flamak i\u00e7in bir i\u015flemde bulunaca\u011f\u0131z:\n",
    "# tracelength ile ge\u00e7mi\u015fte ka\u00e7 zaman ad\u0131m\u0131n\u0131 dikkate alaca\u011f\u0131m\u0131z\u0131 belirliyoruz.\n",
    "# Burada 4 ad\u0131m se\u00e7tik, yani ge\u00e7mi\u015f 4 zaman ad\u0131m\u0131na bakaca\u011f\u0131z.\n",
    "# Bu de\u011fer bizim do\u011fruluk de\u011ferimizi etkileyebilir. Burada ortalama bir de\u011fer olarak 4 kullan\u0131ld\u0131\u011f\u0131 i\u00e7in 4 de\u011ferini se\u00e7tik\n",
    "tracelength = 4\n",
    "\n",
    "# X_raw'u ba\u015flang\u0131\u00e7 olarak X_trace'e at\u0131yoruz.\n",
    "# Daha sonra yukar\u0131da belirtti\u011fimiz miktarda ge\u00e7mi\u015f zaman ad\u0131mlar\u0131yla geni\u015fletece\u011fiz.\n",
    "X_trace = X_raw\n",
    "\n",
    "# Ge\u00e7mi\u015f zaman ad\u0131mlar\u0131n\u0131 X_trace'e eklemek i\u00e7in bir d\u00f6ng\u00fc ba\u015flat\u0131yoruz.\n",
    "for i in range(tracelength):\n",
    "    # X_raw'u i kadar kayd\u0131rarak, ge\u00e7mi\u015f zaman ad\u0131mlar\u0131n\u0131 olu\u015fturuyoruz.\n",
    "    # Daha sonra bu kayd\u0131r\u0131lm\u0131\u015f s\u00fctunlar\u0131 X_trace'e ekliyoruz.\n",
    "    X_trace = pd.concat([X_trace, X_raw.shift(i)], axis=1)  # buradaki X_raw.shift(i); \u00f6rne\u011fin, i=1 i\u00e7in, veriyi 1 ad\u0131m geri kayd\u0131r\u0131r ve b\u00f6ylece ge\u00e7mi\u015f verileri elde etmemizi sa\u011flar.\n",
    "\n",
    "# Yeni s\u00fctun isimlerini d\u00fczenliyoruz. Her s\u00fctun \"S\u00fct\u00fcn0\", \"S\u00fct\u00fcn1\", ..., \"S\u00fct\u00fcn(N)\" \u015feklinde isimlendirilir.\n",
    "X_trace.columns = [\"S\u00fct\u00fcn\" + str(i) for i in range(0, X_trace.shape[1])]\n",
    "\n",
    "# Kayd\u0131rma i\u015flemi sonucu olu\u015flan bo\u015f h\u00fccreleri (NaN) dolduruyoruz. (\u00f6rne\u011fin, ba\u015flang\u0131\u00e7taki ilk 4 ad\u0131mda ge\u00e7mi\u015f veriler eksik olur)\n",
    "# Backfill y\u00f6ntemiyle, bir sonraki ge\u00e7erli de\u011ferle bo\u015fluklar\u0131 dolduruyoruz. Bu sayede eksik veri problemini \u00e7\u00f6zm\u00fc\u015f oluyoruz.\n",
    "X_trace.fillna(method='backfill', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Tahmin etmek istedi\u011fimiz ba\u011f\u0131ml\u0131 de\u011fi\u015fkenleri (enlem ve boylam) se\u00e7iyoruz.\n",
    "y = gt_df[['lat', 'lon']]\n",
    "\n"
   ],
   "metadata": {
    "id": "I3m5luddzvnO"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_raw.iloc[:,:]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "bsJCOnJE8ILh",
    "outputId": "d3f75c89-c320-409d-821b-c9f918818895"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "X_raw.iloc[:,3:]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "FGs13FgA-A79",
    "outputId": "a731d8ac-8eaf-467f-b298-e8fa15c73ea9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# NORMAL\u0130ZASYON i\u015flemimizi uygulayal\u0131m\n",
    "\n",
    "# Verileri -1 ile 1 aras\u0131na \u00f6l\u00e7eklendirebilmek i\u00e7in MinMaxScaler'\u0131 kullan\u0131yoruz.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc = MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "# X_raw ve gt_df[['lat', 'lon']] verilerini numpy array format\u0131na \u00e7eviriyoruz.\n",
    "x_data = np.array(X_raw)\n",
    "y_data = np.array(gt_df[['lat', 'lon']])\n",
    "\n",
    "# X verilerini \u00f6l\u00e7eklendiriyoruz (yani -1 ile 1 aras\u0131na \u00e7ekiyoruz).\n",
    "# Bu ad\u0131m, modelimizin daha verimli \u00f6\u011frenmesine yard\u0131mc\u0131 olacak.\n",
    "new_x_data = sc.fit_transform(x_data)\n",
    "\n",
    "# X verisinin boyutlar\u0131n\u0131 yeniden \u015fekillendiriyoruz \u00e7\u00fcnk\u00fc Derin \u00f6\u011frenme modelleri (\u00f6zellikle LSTM gibi modeller) genellikle 3D bir yap\u0131 bekliyor.\n",
    "# Bu y\u00fczden veriyi (\u00f6rnek say\u0131s\u0131, \u00f6zellik say\u0131s\u0131, 1) \u015feklinde yeniden d\u00fczenliyoruz.\n",
    "new_x_data = new_x_data.reshape(x_data.shape[0], x_data.shape[1], 1)\n",
    "\n",
    "# Ba\u011f\u0131ml\u0131 de\u011fi\u015fken verilerini de ayn\u0131 \u015fekilde \u00f6l\u00e7eklendiriyoruz.\n",
    "# Bu, hedef de\u011fi\u015fkenlerimizin (enlem ve boylam) ayn\u0131 aral\u0131kta olmas\u0131n\u0131 sa\u011flayacak.\n",
    "new_y_data = sc.fit_transform(y_data)\n",
    "\n",
    "# Y verisini daha tutarl\u0131 hale getirmek i\u00e7in, X verisinin ilk iki s\u00fctununu \u00e7\u0131kar\u0131yoruz.\n",
    "# Bu sayede x ve y aras\u0131nda anlaml\u0131 bir ili\u015fki kurmaya \u00e7al\u0131\u015f\u0131yoruz (hizalama i\u015flemi). Bunu yapmasayd\u0131k modeli e\u011fitmemiz daha zor olacakt\u0131 \u00e7\u00fcnk\u00fc x ve y aras\u0131nda bir ili\u015fki kurulmas\u0131 zorla\u015f\u0131rd\u0131\n",
    "# Derin \u00f6\u011frenme modellerinde x ve y aras\u0131ndaki bu uyumu sa\u011flamak \u00f6nemli\n",
    "new_y_data = new_y_data - new_x_data[:, 0:2, 0]\n",
    "\n",
    "\n",
    "\n",
    "print(\"X_data'n\u0131n boyutu :\", x_data.shape)\n",
    "print(\"new_x_data'n\u0131n boyutu :\", new_x_data.shape)\n",
    "\n",
    "print(\"y_data'n\u0131n boyutu :\", y_data.shape)\n",
    "print(\"new_y_data'n\u0131n boyutu :\", new_y_data.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DXrqCHge-KT-",
    "outputId": "42c6fae5-fb2f-4083-e92d-db63fed101a3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 17- LSTM Modelinin Uygulanmas\u0131"
   ],
   "metadata": {
    "id": "omJY4vCOAGOr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf  # TensorFlow k\u00fct\u00fcphanesini i\u00e7e aktar\u0131yoruz.\n",
    "\n",
    "# Keras'\u0131n model ve katmanlar\u0131n\u0131 i\u00e7e aktar\u0131yoruz.\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers.recurrent import LSTM\n",
    "from tensorflow.python.keras.layers.core import Dense, Activation, Dropout\n",
    "\n",
    "# Sklearn k\u00fct\u00fcphanesinden veri \u00f6l\u00e7ekleme, hata hesaplama ve veri b\u00f6lme fonksiyonlar\u0131n\u0131 i\u00e7e aktar\u0131yoruz.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Modeli olu\u015fturuyoruz.\n",
    "model = Sequential()\n",
    "\n",
    "# \u0130lk LSTM katman\u0131n\u0131 ekliyoruz.\n",
    "# units=20 -> 20 LSTM h\u00fccresi kullan\u0131yoruz.\n",
    "# batch_input_shape=(None, new_x_data.shape[1], 1) -> Zaman ad\u0131m\u0131 say\u0131s\u0131n\u0131 ve \u00f6zellik boyutunu belirtiyoruz.\n",
    "# return_sequences=False -> Bu katmandan yaln\u0131zca son \u00e7\u0131kt\u0131y\u0131 al\u0131yoruz.\n",
    "model.add(LSTM(units=20, batch_input_shape=(None, new_x_data.shape[1], 1), return_sequences=False))\n",
    "\n",
    "\n",
    "# \u0130kinci katmanlar\u0131 (hidden layer) ekliyoruz. Ara katmanda relu kullan\u0131yoruz ki kaybolan gradyan problemimiz olmas\u0131n. Relu, \u00f6nemsiz n\u00f6ronlar\u0131n kat say\u0131s\u0131n\u0131 0 yapacak.\n",
    "model.add(Dense(128, activation='relu'))  # 128 n\u00f6ronlu ve ReLU aktivasyon fonksiyonlu bir katman ekliyoruz.\n",
    "model.add(Dense(64, activation='relu'))   # 64 n\u00f6ronlu bir katman ekliyoruz.\n",
    "model.add(Dense(16, activation='relu'))   # 16 n\u00f6ronlu bir katman ekliyoruz.\n",
    "model.add(Dense(4, activation='relu'))    # 4 n\u00f6ronlu katman ekliyoruz.\n",
    "\n",
    "# Dropout katman\u0131 ekleyerek overfitting'i \u00f6nl\u00fcyoruz.\n",
    "# model.add(Dropout(0.2))  # %20 oran\u0131nda rastgele ba\u011flant\u0131lar\u0131 devre d\u0131\u015f\u0131 b\u0131rak\u0131yoruz ki a\u015f\u0131r\u0131 \u00f6\u011frenme olmas\u0131n\n",
    "\n",
    "# \u00c7\u0131k\u0131\u015f katman\u0131n\u0131 ekliyoruz.\n",
    "model.add(Dense(units=2))  # 2 n\u00f6ronlu bir \u00e7\u0131k\u0131\u015f katman\u0131 ekliyoruz (latitude, longitude).\n",
    "\n",
    "# Modeli derliyoruz.\n",
    "# loss='mean_squared_error' -> Ortalama kare hata (MSE) kullanarak kayb\u0131 hesapl\u0131yoruz.\n",
    "# optimizer='adam' -> Adam optimizasyon algoritmas\u0131n\u0131 kullan\u0131yoruz.\n",
    "# metrics=['mae', 'mse' , 'accuracy'] -> Ortalama mutlak hata (MAE) ve MSE'yi ve accuracy'i performans \u00f6l\u00e7\u00fct\u00fc olarak kullan\u0131yoruz.\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse' , 'accuracy'])\n",
    "\n",
    "\n",
    "# Modelin \u00f6zetini ekrana yazd\u0131r\u0131yoruz.\n",
    "model.summary()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZynrlQ-uSAR8",
    "outputId": "11e81f9f-51df-4dc7-a99b-e8251bd6be9f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Tenserflow'da DistributedDatasetInterface \u00f6zelli\u011finin bulunmad\u0131\u011f\u0131 hatas\u0131n\u0131 al\u0131yordum. Onu \u00e7\u00f6zmek i\u00e7in b\u00f6yle bir y\u00f6ntem buldum.\n",
    "\n",
    "from tensorflow.python.keras.engine import data_adapter\n",
    "\n",
    "def _is_distributed_dataset(ds):\n",
    "    return isinstance(ds, data_adapter.input_lib.DistributedDatasetSpec)\n",
    "\n",
    "data_adapter._is_distributed_dataset = _is_distributed_dataset"
   ],
   "metadata": {
    "id": "8orQ_kSoVrrb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Kurudu\u011fumuz a\u011f\u0131 normalize etti\u011fimiz veri setimize fit edelim\n",
    "history = model.fit(new_x_data,new_y_data,epochs=5)\n",
    "\n",
    "\n",
    "# history = model.fit(new_x_data,new_y_data,epochs=10) -> loss: 8.2575e-08 - mae: 2.1054e-04 - mse: 8.2575e-08 - accuracy: 0.8233\n",
    "# history = model.fit(new_x_data,new_y_data,epochs=3) -> loss: 7.5112e-08 - mae: 1.9982e-04 - mse: 7.5112e-08 - accuracy: 0.8444\n",
    "# history = model.fit(new_x_data,new_y_data,epochs=5 , batch_size=32) -> loss: 7.7622e-08 - mae: 2.0202e-04 - mse: 7.7622e-08 - accuracy: 0.8444\n",
    "# history = model.fit(new_x_data,new_y_data,epochs=5 , batch_size=128) -> loss: 7.0668e-08 - mae: 1.9060e-04 - mse: 7.0668e-08 - accuracy: 0.8444\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Az9eHe69SEuw",
    "outputId": "0cc1b137-7058-47a8-f263-8d78cbaf4233"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# \"cannot import name '__version__' from 'tensorflow.python.keras' (/usr/local/lib/python3.11/dist-packages/tensorflow/python/keras/__init__.py)\" hatas\u0131 al\u0131yordum. Bunu d\u00fczeltmek i\u00e7in b\u00f6yle bir i\u015flem yapt\u0131m\n",
    "\n",
    "import tensorflow.python.keras as tf_keras\n",
    "from keras import __version__\n",
    "tf_keras.__version__ = __version__"
   ],
   "metadata": {
    "id": "v5OVfGnOX1sx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.save('/content/drive/MyDrive/BitirmeProjesi/sonuclar/model.h5')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": true,
    "id": "Wo5dn9-OV7Nr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.python.keras.models import load_model\n",
    "model1_epochs5 = load_model('/content/drive/MyDrive/BitirmeProjesi/sonuclar/model.h5')"
   ],
   "metadata": {
    "id": "SFI5ov7-XWOc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.xlabel(\"\u0130terasyon Say\u0131s\u0131\")\n",
    "plt.ylabel(\"Do\u011fruluk Oran\u0131\")\n",
    "plt.title(\"E\u011fitim Accuracy (Do\u011fruluk) Oran\u0131\")\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "3CK71_3XYb62",
    "outputId": "472a4962-9dc5-42eb-fd5c-76fd66c30c18"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(history.history['mse'])\n",
    "plt.xlabel(\"\u0130terasyon Say\u0131s\u0131\")\n",
    "plt.ylabel(\"Ortalama Kare Hata (MSE)\")\n",
    "plt.title(\"E\u011fitim Ortalama Kare Hatas\u0131 (MSE) - Hata Fonksiyonu\")\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "ChkqaaefaOUI",
    "outputId": "2601a3c2-1518-4895-90cb-52c406d0c6b3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Modelden tahmin edilen sonu\u00e7lar\u0131 al\u0131yoruz.\n",
    "# 'new_x_data' verisi \u00fczerinde modelin tahminlerini yap\u0131p, bir d\u00fczeltme uyguluyoruz (ilk iki kolon i\u00e7in).\n",
    "result = model.predict(new_x_data) + new_x_data[:,0:2,0]\n",
    "\n",
    "# Sonu\u00e7lar\u0131 ters d\u00f6n\u00fc\u015f\u00fcm yaparak orijinal \u00f6l\u00e7ek de\u011ferlerine \u00e7eviriyoruz. (MinMax ile normalle\u015ftirmi\u015ftik tersini ald\u0131k. -1,1 aras\u0131na s\u0131k\u0131\u015ft\u0131rm\u0131\u015ft\u0131k)...\n",
    "# ... bunu yapmam\u0131zdaki sebep ger\u00e7ek d\u00fcnyada anlaml\u0131 veriler elde etmek...\n",
    "# ... \u00d6rne\u011fin, modelin tahminleri -1 ile 1 aras\u0131nda olabilir ama bunlar\u0131 ger\u00e7ek d\u00fcnyadaki verilerle kar\u015f\u0131la\u015ft\u0131rabilmek i\u00e7in veriyi ilk ba\u015fta kulland\u0131\u011f\u0131m\u0131z orijinal \u00f6l\u00e7eklerine geri d\u00f6nd\u00fcrmeliyiz.\n",
    "# 'sc' -> sc = MinMaxScaler(feature_range=(-1, 1))\n",
    "res_df = sc.inverse_transform(result)\n",
    "\n",
    "# Predicted (tahmin edilen) ve actual (ger\u00e7ek) GPS koordinatlar\u0131n\u0131 df'e \u00e7eviriyoruz.\n",
    "# 'res_df' ve 'llh_gt' her bir sat\u0131rda bir GPS koordinat\u0131 i\u00e7eriyor.\n",
    "# 'f0' ve 'f1' burada, veri \u00e7er\u00e7evesindeki ilk ve ikinci \u00f6zellikler (enlem ve boylam) i\u00e7in etiketler.\n",
    "predicted_df = pd.DataFrame(data=res_df[0:,0:], index=[i for i in range(res_df.shape[0])], columns=['f'+str(i) for i in range(res_df.shape[1])])\n",
    "actual_df = pd.DataFrame(data=llh_gt[0:,0:], index=[i for i in range(llh_gt.shape[0])], columns=['f'+str(i) for i in range(llh_gt.shape[1])])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Grafi\u011fi G\u00f6rselle\u015ftirelim\n",
    "# 'predicted_df' tahmin edilen GPS noktalar\u0131n\u0131 temsil ediyor.\n",
    "# 'actual_df' ise ger\u00e7ek GPS noktalar\u0131n\u0131 temsil ediyor.\n",
    "plt.scatter(x=predicted_df['f0'], y=predicted_df['f1'], c='red', s=0.5, alpha=0.5, label=\"Tahmin Edilen\")\n",
    "plt.scatter(x=actual_df['f0'], y=actual_df['f1'], c='green', s=0.5, alpha=0.5, label=\"Ger\u00e7ek Veri\")\n",
    "\n",
    "# Grafik ba\u015fl\u0131\u011f\u0131n\u0131 ve eksen etiketlerini belirliyoruz.\n",
    "plt.xlabel(\"Enlem (Latitude)\")\n",
    "plt.ylabel(\"Boylam (Longitude)\")\n",
    "plt.title(\"Tahmin Edilen vs Ger\u00e7ek De\u011ferler\")\n",
    "\n",
    "# Grafik \u00fczerinde g\u00f6sterilen veriler i\u00e7in etiketler ekleyip \u00e7izdiritoruz\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# YORUMLAMA:\n",
    "  # Ger\u00e7ek GPS Verileri (ye\u015fil) , Modelin Tahminleri (k\u0131rm\u0131z\u0131)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "RTpQbexaYhNd",
    "outputId": "083bbf8f-faf7-438a-bb1c-25cb29dcd7e6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "plt.plot(actual_df['f0'], actual_df['f1'], 'g-', label=\"Ger\u00e7ek Yol\")\n",
    "plt.plot(predicted_df['f0'], predicted_df['f1'], 'r--', label=\"Tahmin Edilen Yol\")\n",
    "plt.xlabel(\"Enlem (Latitude)\")\n",
    "plt.ylabel(\"Boylam (Longitude)\")\n",
    "plt.title(\"Ger\u00e7ek vs Tahmin Edilen Yol\")\n",
    "plt.legend()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "DTbi6oVswNw3",
    "outputId": "f1fe385e-0a97-4157-8d8a-3911a5e6fee5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Hata mesafelerini hesapla\n",
    "error_distances = vincenty_distance(res_df, llh_gt)\n",
    "\n",
    "# Hata mesafelerini DataFrame'e ekle\n",
    "error_df = pd.DataFrame({'lat': llh_gt[:, 0], 'lon': llh_gt[:, 1], 'error': error_distances})\n",
    "\n",
    "# Harita \u00fczerinde hata da\u011f\u0131l\u0131m\u0131n\u0131 g\u00f6ster\n",
    "fig = px.scatter_mapbox(error_df, lat=\"lat\", lon=\"lon\", color=\"error\",\n",
    "                        zoom=12, center={\"lat\": 37.45, \"lon\": -122.27},\n",
    "                        height=600, width=1000,\n",
    "                        color_continuous_scale=px.colors.sequential.Reds,\n",
    "                        title=\"Hata Da\u011f\u0131l\u0131m\u0131\")\n",
    "fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "fig.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "id": "5C88eRbaaCuX",
    "outputId": "193829fb-0d55-405e-b878-38db57c23395"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Ger\u00e7ek GPS verisi (llh_gt) ile model taraf\u0131ndan tahmin edilen konum (res_df) aras\u0131ndaki fark\u0131 hesaplayal\u0131m\n",
    "vd_nn = vincenty_distance(res_df, llh_gt)\n",
    "\n",
    "# Modelin do\u011frulu\u011funu de\u011ferlendirmek i\u00e7in hata skoru hesaplayaca\u011foz\n",
    "# Tahmin edilen konumlar (res_df) ve ger\u00e7ek konumlar (llh_gt) aras\u0131ndaki hata metri\u011fini kullanaca\u011f\u0131z bunu yaparken\n",
    "score_nn = calc_score(res_df[:-1, :], llh_gt[:-1, :])\n",
    "\n",
    "# Farkl\u0131 y\u00f6ntemlerle elde edilen hata skorlar\u0131:\n",
    "print(f'Referans Noktas\u0131 (Baseline) Skoru: {score_bl:.4f} [metre]')\n",
    "print(f'WLS Y\u00f6ntemi Skoru: {score_wls:.4f} [metre]')\n",
    "print(f'Kalman Filtresi Skoru: {score_kf:.4f} [metre]')\n",
    "print(f'YSA (LSTM) Skoru:   {score_nn:.4f} [m]')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MWtU52QsYkIN",
    "outputId": "f9b88d65-bc81-4ac4-83d2-090f653aa9f0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "BE8aXQ-JYm_-",
    "outputId": "a2e44993-beaa-4a26-c7e8-7f6a640f46bc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Modelin Performans\u0131n\u0131 Kar\u015f\u0131la\u015ft\u0131ran Grafikler\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(range(len(vd_bl)), vd_bl, label=\"Baseline\")\n",
    "plt.plot(range(len(vd_wls)), vd_wls, label=\"WLS\")\n",
    "plt.plot(range(len(vd_kf)), vd_kf, label=\"Kalman Filtresi\")\n",
    "plt.plot(range(len(vd_nn)), vd_nn, label=\"LSTM\")\n",
    "\n",
    "plt.xlabel(\"Zaman [sn]\")\n",
    "plt.ylabel(\"Hata Mesafesi [m]\")\n",
    "plt.title(\"Modellerin Hata Kar\u015f\u0131la\u015ft\u0131rmas\u0131\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "WCSeeD7aa1zh",
    "outputId": "c04c251b-e32c-4660-e886-ade0d6fef23a"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}